Skip to main content
Autonomous Task Decomposition for Robotics
December 28, 2025
How can a system orchestrator utilize Large Language Models to autonomously decompose a mission into sub-tasks and allocate them based on the differing hardware constraints of multiple robotic agents?
A system orchestrator can utilize Large Language Models to autonomously decompose missions into sub-tasks and allocate them based on hardware constraints by employing hybrid architectures that combine centralized LLM reasoning with distributed execution, using dependency graphs or hierarchical structures for task decomposition, integrating robot capability information through structured prompts or "robot resume" representations, and pairing LLM-based reasoning with classical optimization methods such as integer programming or PDDL planners to ensure allocation decisions respect hardware limitations while maintaining coordination across heterogeneous robot teams.
Abstract
This systematic review of 80 sources reveals that LLM-based system orchestrators can effectively decompose missions and allocate tasks across heterogeneous robot teams through three primary architectural approaches: centralized, decentralized, and hybrid systems. Hybrid architectures combining centralized LLM oversight with distributed execution consistently achieve the highest success rates and scalability. Mission decomposition is accomplished through dependency-aware techniques including Directed Acyclic Graphs for modeling task precedence, hierarchical tree structures, and Chain-of-Thought prompting for structured reasoning. Hardware constraints are integrated into LLM reasoning through several mechanisms: “robot resume” approaches that generate capability descriptions from URDF files, skill-based representations encoded in structured prompts, and dynamic capability vectors enabling real-time state tracking. Systems achieve success rates of 94-100% on structured tasks when combining LLM reasoning with classical optimization methods such as integer programming or PDDL planners, outperforming pure LLM approaches in allocation optimality.

Key limitations constrain practical deployment: centralized systems face context window limitations that degrade performance beyond approximately 10 robots, LLM hallucinations compromise reliability in safety-critical scenarios, and computational demands often preclude on-robot execution, requiring cloud connectivity or model compression techniques. Effective systems address these challenges through feedback mechanisms such as the PEFA loop and digital twin synchronization that enable dynamic re-planning, human-in-the-loop verification for safety assurance, and hybrid LLM-optimization pipelines that leverage LLM flexibility for decomposition while ensuring allocation optimality through formal methods. The evidence strongly supports that autonomous mission decomposition and hardware-aware allocation is achievable with current LLM capabilities, though robust deployment requires careful integration with classical planning and optimization techniques rather than reliance on LLM reasoning alone.

We analyzed 80 sources from an initial pool of 500, using 5 screening criteria. Each paper was reviewed for 8 key aspects that mattered most to the research question. More on methods
Characteristics of Included Studies
This systematic review synthesizes findings from 80 sources examining the use of Large Language Models for autonomous mission decomposition and task allocation in multi-robot systems. The studies span various application domains and employ diverse methodological approaches.






Yongdong Wang et al., 2024

Yes

Primary study

Dependency-aware task decomposition

Tracked robots, excavators

Tinging Yang et al., 2025

No

Primary study

Heterogeneous multi-agent coordination

Drones, ground robots

Zhehui Huang et al., 2025

Yes

Primary study

Compositional multi-robot coordination

Not specified

Wenhao Yu et al., 2024

Yes

Primary study

Decentralized heterogeneous collaboration

Mobile, manipulation, mobile-manipulation

Jun Wang et al., 2024

No

Primary study

Safe task planning with conformal prediction

Not specified

Yongchao Chen et al., 2023

Yes

Primary study

Centralized vs decentralized planning comparison

Robot arms, mobile manipulators

Xiaopan Zhang et al., 2024

Yes

Primary study

LLM-PDDL integration for long-horizon tasks

Ground robots/manipulators

Jun Wang et al., 2024a

Yes

Primary study

Probabilistically correct planning

Ground robots/manipulators

Min Deng et al., 2025

Yes

Primary study

Construction robotics with digital twins

Manipulators

Kehui Liu et al., 2024

Yes

Primary study

Heterogeneous multi-robot collaboration

Quadrotors, robotic dogs, arms

The studies predominantly represent primary research contributions, with one comprehensive survey. Approximately 50% of studies provided full text access, while the remainder were analyzed through abstracts. The research covers diverse robotic platforms including UAVs, ground robots, manipulators, and heterogeneous multi-robot teams operating across domains such as household robotics, construction, search and rescue, agriculture, and autonomous transportation.

System Architectures for LLM-Based Multi-Robot Orchestration
The integration of LLMs into multi-robot systems follows three primary architectural paradigms: centralized, decentralized, and hybrid approaches. Each architecture presents distinct trade-offs between coordination efficiency, scalability, and robustness.

Centralized Architectures
Centralized systems employ a single LLM as the primary decision-maker for mission decomposition and task allocation. The SMART-LLM framework uses LLMs as central planners to autonomously decompose missions into sub-tasks and allocate them based on robot skills and environment details. Similarly, LaMMA-P integrates LLMs as a central component for task decomposition and allocation, generating PDDL problem descriptions for downstream planning. The COHERENT framework implements a centralized hierarchical structure where a centralized task assigner decomposes tasks and assigns them to distributed robot executors.

AutoRT demonstrates large-scale centralized orchestration, with LLMs generating tasks based on visual observations for deployment across over 20 robots. The EMOS framework employs a hierarchical centralized approach where a leader LLM agent coordinates with robot-specific agents through a star topology.

Decentralized Architectures
Decentralized systems distribute LLM reasoning across individual robots, enabling autonomous local decision-making. The MHRC framework supports decentralized collaboration where each robot type has independent planning capabilities through LLM-driven decision modules. S-ATLAS implements a decentralized LLM-based planner where each robot uses its own LLM agent to select actions based on context and previous decisions.

The HMCF framework equips each robot with an LLM agent capable of understanding its capabilities and converting tasks into executable instructions. LLM-Flock provides each robot with its own LLM for local planning, combined with an influence-based consensus protocol for coordination. The SAMALM framework employs a decentralized multi-agent LLM actor-critic structure where parallel LLM actors generate control signals independently.

Hybrid Architectures
Hybrid architectures combine centralized oversight with distributed execution, emerging as the dominant approach across studies. The comparative study by Chen et al. demonstrates that hybrid frameworks (HMAS-1 and HMAS-2) achieve better task success rates and scale better to more agents than purely centralized or decentralized approaches.

AutoHMA-LLM implements a multi-tier architecture utilizing a cloud-based LLM as the central planner alongside device-specific LLMs. The hierarchical LLM framework by Wu et al. integrates LLMs into multiple feedback loops with conventional optimizers, where an outer loop provides strategic guidance and an inner loop handles reactive adaptations. DART-LLM uses a hybrid approach combining LLMs with classical control algorithms for navigation and robot-specific skills.

The RoCo framework employs LLMs for both high-level communication and low-level path planning, with centralized RRT-based motion planning for parallel execution. The DELIVER framework combines high-level LLM-based planning with low-level FSM-based execution through Voronoi tessellation for spatial decomposition.





Centralized

SMART-LLM, LaMMA-P, AutoRT

Single LLM decision-maker, simplified coordination

Limited by context window

Decentralized

MHRC, S-ATLAS, HMCF

Independent robot LLMs, local decision-making

Better with more agents

Hybrid

HMAS-2, AutoHMA-LLM, DART-LLM

Central oversight with distributed execution

Best overall

The hybrid HMAS-2 structure achieves the highest success rate while maintaining reasonable token efficiency. This architectural pattern is particularly effective for long-horizon, heterogeneous multi-robot planning where both global coordination and local autonomy are essential.

Mission Decomposition Methods
The autonomous decomposition of high-level missions into executable sub-tasks represents a core capability enabled by LLMs in multi-robot systems. The reviewed literature reveals several distinct approaches to mission decomposition.

Hierarchical and Graph-Based Decomposition
Dependency graphs and hierarchical structures are widely employed to represent task relationships. DART-LLM uses Directed Acyclic Graphs (DAGs) to model subtask dependencies, enabling parallel execution of independent subtasks. Similarly, LiP-LLM constructs dependency graphs using LLMs to map sequential constraints among skills, with linear programming optimizing task allocation.

The LAN2CB framework parses missions into task graphs with dependencies through a Mission Decomposition component, capturing execution topologies through behavior tree structures. DEXTER-LLM employs directed acyclic graphs for task representation with temporal constraints derived through multi-stage LLM prompting. The Nl2Hltl2Plan framework transforms natural language into Hierarchical Task Trees capturing logical and temporal relations before converting sub-tasks into flat LTL formulas.

Gupta et al. propose using hierarchical trees systematically constructed by LLMs to break down complex missions into manageable sub-tasks, with specialized APIs facilitating tree construction.

Prompting Strategies for Decomposition
Chain-of-Thought (CoT) prompting emerges as a dominant technique for structured reasoning during task decomposition. The GMATP-LLM framework uses CoT prompting to transform high-level task instructions into sets of sub-tasks. RALLY implements a two-stage structured prompting approach with local intention generation and neighborhood consensus refinement.

Few-shot prompting strategies are employed across multiple systems. LaMMA-P uses few-shot filling prompts for task decomposition and allocation. Murata et al. design a novel few-shot prompting strategy enabling LLMs to infer required objects from ambiguous commands and decompose them into appropriate subtasks. SMART-LLM uses Pythonic prompts with detailed comments to guide task decomposition.

The Zero-shot-CoT procedure combined with cue word iteration methods enhances decision-making efficiency for adversarial multi-robot games. SafePlan employs Prompt Sanity COT Reasoner and Invariant COT Reasoner to evaluate task prompts through multiple verification stages.

Multi-Stage Reasoning Processes
Iterative refinement processes characterize many decomposition approaches. The PEFA (Proposal-Execution-Feedback-Adjustment) mechanism in COHERENT enables iterative plan adjustment based on execution feedback. RoCo validates plans step-by-step with environmental feedback until valid plans are achieved.

LLaMAR implements a plan-act-correct-verify framework where the Planner suggests subtasks, the Actor predicts actions, the Corrector self-corrects based on failures, and the Verifier assesses completion. The CRAFT framework uses VLM-guided reward-refinement loops for iterative task decomposition.





DAG-based

DART-LLM, LiP-LLM, DEXTER-LLM

Explicit graph constraints

Natural language

Hierarchical trees

LAN2CB, Gupta et al.

Tree structure ordering

Natural language

CoT prompting

GMATP-LLM, RALLY

Implicit through reasoning

Natural language

LTL integration

Nl2Hltl2Plan, SafePlan

Temporal logic formulas

Natural language, LTL

PDDL integration

LaMMA-P, PLANTOR

PDDL problem constraints

Natural language, PDDL

Support for Multiple Mission Specification Formats
Several frameworks support translation between mission specification formats. Nl2Hltl2Plan translates natural language commands into hierarchical Linear Temporal Logic. SafePlan uses LTL for formalizing safety properties and supports natural language inputs. The PLANTOR framework converts plans into Behaviour Trees for direct use in ROS2.

Dan BW Choe et al. transform natural language requests into Signal Temporal Logic (STL) specifications using BNF grammar, which are then solved as Mixed Integer Linear Programs. DEXTER-LLM translates mission objectives into verifiable LTL formulas for abstraction of tasks and temporal relations.

Hardware Constraint Modeling
Effective task allocation in heterogeneous multi-robot systems requires accurate representation of robot capabilities and limitations. The reviewed literature presents diverse approaches to modeling and integrating hardware constraints into LLM reasoning processes.

Types of Hardware Constraints Addressed
The studies address multiple categories of hardware constraints:

Mobility constraints are most commonly considered, including movement capabilities, traversability, and navigation skills. The HMCF framework tracks robot specifications including traversability and the ability to ascend/descend stairs.

Payload and manipulation constraints are addressed through skill-based representations. Chen et al. define different lifting capabilities for robot arms. SMART-LLM includes payload constraints such as maximum mass a robot can pick up. The SAFER framework considers joint position limits, velocity limits, and torque limits.

Sensing constraints are incorporated through observation specifications. The MHRC framework includes sensing capabilities in its observation module. CoordField represents patrol UAVs with wide-area scanning and tracking UAVs with precise target following capabilities.

Computational constraints affect LLM deployment strategies. LLM-MARS notes that robots’ hardware is often not capable of running LLMs locally, requiring remote server execution. RALLY addresses resource-constrained architectures through lightweight LLM versions.

Methods for Representing Robot Capabilities
Robot Resume Approach: The EMOS framework introduces “Robot Resume,” where agents comprehend robot URDF files and call robot kinematics tools to generate descriptions of physics capabilities. This self-prompted approach creates textual summaries and numerical representations of mobility, perception, and manipulation capabilities.

Skill-Based Representations: DART-LLM defines skill sets for each robot and team, with task assignment based on individual robot skills. S-ATLAS represents capabilities as textual skills (e.g., ‘take a picture’, ‘grab’, ‘go to’). SMART-LLM encodes robot skills as Python dictionaries with specific constraints.

Capability Vectors: CoordField uses a dynamic capability vector c_i(t) representing each UAV’s current capabilities. The digital twin framework by Deng et al. employs a capability model defining task requirement constraints based on available and required capabilities.

Natural Language Descriptions: The LLM-to-TL framework represents capabilities in natural language (e.g., “can lift pallets” or “max speed 1 m/s”). SayCoNav shares background information about each robot’s skills and operational constraints through text.




Mobility

Skill sets, capability vectors

DART-LLM, CoordField

Payload

Maximum limits, skill constraints

SMART-LLM, Chen et al.

Sensing

Observation specifications

MHRC, RALLY

Computational

Remote execution, model compression

LLM-MARS, RALLY

Communication

Protocol specifications, connectivity

DELIVER, LLM-Flock

Integration with LLM Reasoning
Hardware constraints are integrated into LLM reasoning through several mechanisms:

Structured Prompts: The hierarchical LLM framework provides comprehensive information about robot capabilities and current status to the task LLM through structured prompts. LaMMA-P integrates capability information through generation of PDDL problem descriptions for each robot’s domain.

Context Aggregation: COHERENT fuses robot capabilities with observations and task requirements into long text prompts for the task assigner LLM. EMOS uses robot resumes in prompts for embodiment-aware reasoning.

Feedback Mechanisms: The digital twin framework enables closed-loop feedback for real-time updates and task allocation refinement based on changing hardware states. HMCF implements regular status updates from robots to LLM agents for task reallocation.

Handling Heterogeneous Robot Teams
Approaches for managing heterogeneity include:

Coalition Formation: SMART-LLM addresses skill gaps by involving additional robots through coalition formation policies. EMOS assigns tasks based on embodiment-aware reasoning using robot resumes.

Dynamic Role Assignment: CoordField divides UAVs into patrol and tracking types with differing sensing capabilities. SayCoNav automatically generates collaboration strategies leveraging diverse robot skills.

Capability Matching: The digital twin framework ensures collective possession of required capabilities by assigned robot teams. LaMMA-P uses a modular design for flexible task decomposition based on varying robot skills.

Dynamic Adaptation to Hardware States
Several systems implement mechanisms for adapting to changing hardware conditions:

Real-time Status Monitoring: HMCF requests regular updates from robots regarding status and task progress. The digital twin framework provides real-time synchronization between physical and digital models.

Failure Detection and Compensation: AquaChat++ incorporates thruster fault detection and compensation mechanisms with event-triggered replanning. SayCoNav re-generates collaboration strategies when a robot’s physical condition changes during navigation.

Task Allocation Mechanisms
Task allocation represents the critical bridge between mission decomposition and execution. The reviewed literature presents diverse algorithmic approaches ranging from optimization-based methods to pure LLM reasoning.

Optimization-Based Approaches
Integer and Linear Programming: The digital twin framework by Deng et al. uses an Integer Programming model solved with a CP-SAT solver, optimizing makespan while penalizing robot assignment counts. LiP-LLM employs linear programming for task allocation based on skill feasibility and distance metrics. PLANTOR uses mixed-integer linear programming for resource allocation and temporal planning.

Mathematical Optimization Integration: Dan BW Choe et al. solve Signal Temporal Logic specifications as Mixed Integer Linear Programs using Gurobi. The hierarchical LLM framework formulates a bi-level optimization problem with LLMs modifying both levels.

Search-Based Methods: DEXTER-LLM employs branch-and-bound search with integer programming to minimize maximum ending time while respecting constraints. LAN2CB uses a minimal conflict strategy to minimize trajectory intersections during goal allocation.

Heuristic and Learning-Based Approaches
Auction Mechanisms: MTU-LLM implements K-means clustering for task grouping with distance-based bidding for matching victim requirements to robot capabilities. The OATH framework uses weighted auctions within a cluster-auction-selection framework.

Reinforcement Learning Integration: RALLY employs an RMIX-based credit-assignment mechanism combining LLM offline priors with MARL online policies. ICCO uses Multi-Agent Reinforcement Learning jointly trained with LLM-generated instructions.

Consensus Protocols: LLM-Flock uses an influence-based consensus protocol where robots negotiate and adopt plans based on influence scores. RALLY implements a two-stage consensus generation strategy for distributed decision-making.

LLM-Native Allocation
Several systems rely primarily on LLM reasoning for allocation decisions:

Direct LLM Allocation: SMART-LLM generates executable code for task planning through Pythonic prompts without separate optimization. RoCo uses dialog-based planning with feasibility checks through LLM reasoning.

Hybrid LLM-Optimization: LaMMA-P integrates LLM-based task decomposition with PDDL planners for detailed action sequences. GMATP-LLM combines LLM reasoning capabilities with intelligent PDDL planners.





Integer Programming

IP/MILP solvers

Limited

Explicit constraints

Linear Programming

LP optimization

Moderate

Skill feasibility

Auction-based

Distance bidding

Good

Clustering

MARL-integrated

RL optimization

Good

Learned

LLM-native

Prompt-based

Good

LLM reasoning

Search-based

Branch-and-bound

Limited

Graph constraints

Real-Time vs Offline Allocation
Real-time Systems: SayCoNav continuously updates plans based on shared information during navigation. COHERENT uses real-time allocation through the PEFA mechanism. The DELIVER framework implements real-time allocation with finite-state machines for coordination.

Offline/Batch Processing: HVBTA uses pre-trained LLMs for suitability assessment in modular construction. MTU-LLM focuses on offline allocation ensuring workload balance.

Hybrid Approaches: The hierarchical LLM framework updates the task LLM every 20-30 seconds while the action LLM updates every 5 seconds. DEXTER-LLM dynamically adapts to new tasks through event-based module retriggering.

Parallel Execution and Load Balancing
Parallel Task Management: DART-LLM enables parallel execution of independent subtasks through DAG-based decomposition. LAN2CB generates code simultaneously for multiple action nodes in behavior trees. DynTaskMAS uses sophisticated scheduling algorithms to maximize parallelism while respecting dependencies.

Load Balancing: DELIVER reduces per-agent workload by up to 55% compared to single-agent systems while maintaining low coordination overhead. MTU-LLM demonstrates better workload balance compared to baseline approaches. DynTaskMAS employs a greedy allocation strategy to balance load across agents.

Performance Evaluation
The reviewed studies present diverse performance metrics demonstrating the effectiveness of LLM-based multi-robot orchestration systems.

Success Rates and Accuracy
Success rates vary significantly across systems and task complexity levels:





DART-LLM

L1/L2/L3 tasks

100%/97%/94%

Outperforms SMART-LLM

LaMMA-P

Household tasks

105% higher than baselines

vs. SMART-LLM, CoT

S-ATLAS

Multi-robot planning

94.59-96.57%

vs. CMAS, DMAS

HMCF

Heterogeneous tasks

92.4%

4.76% improvement

LLaMAR

Long-horizon tasks

30% higher

vs. state-of-the-art

DEXTER-LLM

All scenarios

100%

3x more tasks than baselines

SafePlan

Safety verification

84-95%

90.5% reduction in harmful prompts

SMART-LLM achieves 70% success in compound and complex tasks with GPT-4 and 100% in elemental tasks. The Murata et al. framework achieves 47/50 successful assignments compared to 28/50 for random assignment. LLM-MARS demonstrates 79.28% average task execution accuracy for compound commands, exceeding 90% for commands with up to two tasks.

Efficiency Metrics
Communication Efficiency: AutoHMA-LLM achieves a 46% reduction in communication steps and 31% decrease in token usage. S-ATLAS requires fewer LLM queries compared to centralized approaches. DEXTER-LLM requires 62% fewer LLM queries during adaptation.

Computational Efficiency: MTU-LLM demonstrates a tenfold reduction in average computation time (0.033s vs 0.596s). DynTaskMAS achieves 21-33% reduction in execution time across task complexities with 35.4% improvement in resource utilization. LAMARL improves sample efficiency by 185.9% through prior policy generation.

Planning Time: LiP-LLM shows shorter process times through combinatorial optimization. The average runtime for S-ATLAS to design a plan is 0.4 minutes.

Scalability Results
Scalability assessments reveal both capabilities and limitations:

Positive Scalability Findings: HMAS-2 scales better to more agents than CMAS. DynTaskMAS achieves near-linear throughput scaling up to 16 concurrent agents. LLaMAC is applied to tasks involving more than 50 agents. S-ATLAS shows increased advantage over baselines with larger robot teams.

Scalability Challenges: HMCF identifies scalability as a challenge for large-scale deployments involving dozens or hundreds of robots. DynTaskMAS shows diminishing returns at 32 agents. Centralized approaches face context window limitations that constrain scalability.

Comparison with Baseline Methods
Studies consistently demonstrate LLM-based approaches outperforming traditional methods:

vs. Rule-Based Methods: CoELA driven by GPT-4 surpasses MCTS-based and rule-based hierarchical planners by more than 40% in efficiency. COHERENT achieves the highest success rate compared to primitive MCTS and LLM-MCTS.

vs. Pure Optimization: LiP-LLM outperforms RoCo and SMART-LLM in success rates and process times. SAFER reduces safety violations by 77.5% compared to state-of-the-art LLM planners.

vs. Reinforcement Learning: LGC-MARL achieves higher success rates with lower normalized token costs compared to centralized LLM methods. L2M2 requires less than 20% of training samples compared to baseline MARL methods.

Identified Limitations
Several limitation categories emerge across studies:

LLM-Specific Limitations: CoELA shows unstable performance on complex reasoning tasks due to limited 3D spatial reasoning. LLaMAR performance is limited by the underlying VLM’s spatial reasoning capabilities. EMOS faces challenges with hallucinations in LLMs.

Computational Constraints: LLM-Flock identifies computational demands as a significant limitation requiring model compression or hardware acceleration. Higher computational costs are noted due to multiple LLM queries.

Environmental Assumptions: LaMMA-P assumes fully observable, static environments. RoCo is limited by assumptions of accurate perception and open-loop execution.

Dynamic Adaptation
Real-world multi-robot deployments require systems capable of responding to changing conditions, failures, and evolving mission requirements.

Methods for Detecting Changes
Trigger-Based Detection: LAN2CB uses trigger conditions to detect changes during execution, updating dependency analysis accordingly. DEXTER-LLM re-triggers modules in response to new events detected during operation.

Continuous Monitoring: The digital twin framework provides real-time synchronization between physical operations and digital representations. SayCoNav detects changes in robot physical conditions during navigation. CoordField continuously monitors UAV status reports for environmental changes.

Feedback Integration: COHERENT’s PEFA mechanism enables continuous feedback and adjustment based on execution results. MHRC uses textual feedback mechanisms and CoT prompts for change detection.

Re-Planning and Re-Allocation Strategies
Iterative Re-Planning: RoCo re-plans based on environmental feedback until valid plans are achieved or maximum attempts reached. LLaMAR’s Corrector module adjusts actions based on failures. The hierarchical LLM framework implements frequent updates with the task LLM triggered every 20-30 seconds.

Dynamic Behavior Trees: The LLM-HBT framework enables dynamic extension of behavior trees and invocation of a centralized coordinator for subtask reassignment upon failure. LLM-MARS allows rapid reorganization to accommodate new tasks through behavior tree regeneration.

Optimization-Based Re-Allocation: The digital twin framework implements replanning optimization minimizing makespan while penalizing deviations from original plans. DEXTER-LLM uses search-based optimization for task reassignment upon robot failure.

Human-in-the-Loop Mechanisms
Multiple frameworks incorporate human oversight for enhanced safety and adaptability:

Direct Intervention: HMCF enables real-time human oversight and intervention through commands to robots. William Hunt et al. allow human advisors to interrupt and check plans with agents. DEXTER-LLM implements online verification and confirmation by human operators.

Supervisory Control: The hierarchical LLM framework incorporates real-time human input for feedback on performance and environmental hazards. The digital twin framework includes a user command receiver module for interventions.

Narrative-Based Adaptation: The construction robotics framework enables narrative-driven schedule adaptation using LLMs to interpret natural language inputs for constraint updates.





PEFA loops

Execution feedback

Real-time

Optional

Behavior tree extension

Failure detection

Real-time

None

Digital twin sync

Status change

Real-time

Command receiver

Trigger conditions

Mission events

Event-based

None

Confidence thresholds

Uncertainty levels

On-demand

Help requests

Event-Based vs Periodic Updates
Event-Based Systems: LAN2CB updates based on trigger conditions during execution. DEXTER-LLM employs event-based module retriggering. The conformal prediction approach in S-ATLAS enables robots to seek help when uncertainty exceeds thresholds.

Periodic Updates: The hierarchical LLM framework refreshes the outer LLM every 8-10 steps and the action LLM every 5 seconds. LLM-Flock implements periodic position updates between plan consensus and motion execution.

Hybrid Approaches: The digital twin framework combines event-based updates through user interventions with periodic real-time synchronization. BioMARS uses WebSocket protocols for event-based communication while maintaining continuous monitoring.

LLM Implementation Details
The practical implementation of LLM-based multi-robot orchestration involves careful selection of models, prompting strategies, and efficiency optimizations.

LLM Models Employed
GPT Family: GPT-4 and variants are most commonly employed, including GPT-4o, GPT-3.5-turbo, and GPT-4-vision. AutoHMA-LLM uses GPT-4o-mini alongside GPT-4o.

Open-Source Models: Llama models are widely used including Llama-3.1-8B, Llama-2-7b/13b, and LLaMA3. Qwen models appear across multiple studies including Qwen-72B, Qwen-32B, and Qwen-7B. DeepSeek-R1 and Claude variants are also employed.

Specialized Models: LLM-MARS fine-tunes the Falcon 7B model with LoRA adapters. REMALIS uses a custom 7 billion parameter model. GTE-Base is used for language-conditioned navigation.




GPT-4 variants

GPT-4o, GPT-4-vision

Central planning, complex reasoning

Llama family

Llama-3.1-8B, Llama-2-70b

Local deployment, fine-tuning

Qwen models

Qwen-72B, Qwen2.5-32b

Balanced performance

Specialized

Falcon-7B, custom 7B

Domain-specific tasks

Prompting Strategies
Chain-of-Thought: CoT prompting is widely employed for structured reasoning. GMATP-LLM uses CoT for task decomposition and assignment. Zero-shot chain-of-thought prompting is used in CoELA to encourage more reasoning.

Few-Shot Learning: LaMMA-P uses few-shot filling prompts. PLANTOR employs few-shot prompting combined with CoT. The digital twin framework uses few-shot learning for constraint extraction.

Structured Prompts: DART-LLM uses structured prompts including instruction, environment, robot set, skills, and few-shot examples. SMART-LLM employs Pythonic prompts with line-by-line comments. Hierarchical prompts integrate essential information in multi-stage structures.

Multi-Agent LLM Configurations
Specialized Roles: SAFER employs separate Task Planning LLM and Safety Planning LLM agents. LLaMAR uses four specialized modules (Planner, Actor, Corrector, Verifier). BioMARS uses distinct Biologist Agent and Technician Agent.

Hierarchical Agents: The hierarchical LLM framework uses outer and inner loop LLMs with different responsibilities. COHERENT implements a centralized task assigner with individual robot executors each having independent LLMs.

Decentralized Agents: HMCF equips each robot with its own LLM agent. LLM-Flock provides each robot with its own LLM for local planning.

Vision-Language Model Integration
Several frameworks integrate VLMs for enhanced perception:

Object Detection: DART-LLM uses VLM-based object detection for object map database updates. RoCo integrates with perception systems for environment understanding.

Scene Understanding: Dan BW Choe et al. use VLMs for conflict detection and description. The aerial-ground framework integrates GridMask-enhanced fine-tuned VLM. UAV-CodeAgents fine-tunes Qwen2.5VL-7B on annotated satellite images.

Visual Monitoring: BioMARS employs VLMs for hierarchical visual monitoring with geometric and semantic validation.

Efficiency Optimization Strategies
Query Reduction: LiP-LLM uses linear programming to reduce reliance on LLM inference. BOLAA orchestrates specialized agents to reduce individual query loads. S-ATLAS employs parallel querying of GPT-3.5 while sequentially querying Llama models.

Model Compression: LLM-Flock suggests model compression, distillation, or hardware acceleration for deployment. DynTaskMAS uses INT8 quantization for efficient inference. RALLY fine-tunes smaller models using LLaMA-Factory with LoRA.

Caching and Memory: HMCF uses Retrieval-Augmented Generation to reduce redundant queries. The digital twin framework implements narrative-driven updates to minimize unnecessary re-computation.

Synthesis
The heterogeneity in findings across the reviewed literature can be explained through several key factors that influence when different approaches succeed or fail.

Architectural Trade-offs Across Deployment Contexts
The choice between centralized, decentralized, and hybrid architectures is not simply a design preference but reflects fundamental trade-offs that apply differently across contexts. Centralized approaches like SMART-LLM and AutoRT excel in scenarios with stable communication infrastructure and moderate robot counts (typically under 10), achieving high coordination efficiency through unified reasoning. However, their performance degrades with increasing team size due to context window limitations and communication bottlenecks.

Decentralized systems like MHRC and S-ATLAS scale more gracefully to larger teams (demonstrated with 50+ agents in LLaMAC) but face coordination challenges in tightly coupled tasks requiring precise synchronization. The hybrid HMAS-2 approach achieves the best success rates across task types because it combines centralized oversight for global coordination with distributed execution for scalability, a pattern applicable when both coordination precision and scalability matter.

Task Complexity and Decomposition Strategy Matching
The effectiveness of decomposition methods depends critically on task characteristics. DAG-based approaches (DART-LLM, LiP-LLM) excel for tasks with clear precedence relationships and independent subtasks enabling parallel execution, achieving 94-100% success rates on structured tasks. However, these approaches require well-defined dependency structures that may not exist for exploratory or adaptive missions.

CoT prompting methods (GMATP-LLM, RALLY) handle more ambiguous task specifications but show higher variability in outcomes, particularly for complex reasoning requiring multiple reasoning steps. The few-shot prompting strategy by Murata et al. achieves 94% success (47/50) on ambiguous commands because it provides exemplars that ground the LLM’s reasoning in domain-appropriate patterns.

LTL integration (Nl2Hltl2Plan, SafePlan) provides formal guarantees for safety-critical applications but requires users to specify or accept temporal logic constraints, limiting accessibility for non-expert operators.

Hardware Constraint Modeling Depth and Allocation Accuracy
Studies employing rich capability representations consistently outperform those with minimal constraint modeling. The “robot resume” approach (EMOS) achieves higher success rates in embodiment-aware tasks because it explicitly captures physics capabilities that pure skill-based representations miss. The digital twin framework with dynamic capability modeling enables adaptive task allocation that responds to real-time hardware state changes.

Conversely, systems assuming homogeneity (S-ATLAS initially assumes shared skill sets) or using only coarse capability categories show degraded performance when hardware heterogeneity is high. The MTU-LLM framework achieves better workload balance by explicitly encoding capability-requirement matching in its prompt structure.

Real-Time Adaptation Capability and Environmental Dynamics
Systems with continuous feedback integration (PEFA mechanism, digital twin synchronization) maintain higher success rates in dynamic environments compared to open-loop planners. RoCo’s re-planning approach achieves success through iterative validation, but introduces latency that may be unacceptable for time-critical applications.

The hierarchical LLM framework’s multi-rate update strategy (task LLM every 20-30 seconds, action LLM every 5 seconds) represents a principled trade-off between adaptation responsiveness and computational cost. This tiered approach explains why it handles real-time target tracking while systems with single-rate updates struggle with rapidly changing conditions.

Model Selection and Computational Context
GPT-4 variants consistently achieve higher success rates than smaller models (e.g., GPT-4o achieving 0.75-0.92 success rates vs. GPT-3.5-turbo’s lower performance), but at significantly higher computational cost and latency. For edge deployment scenarios, fine-tuned smaller models like Llama-3.1-8B with LoRA provide viable alternatives when combined with structured prompting.

The success of Falcon 7B fine-tuned with LoRA for behavior tree generation demonstrates that domain-specific fine-tuning can compensate for reduced model capacity when task scope is well-defined. Similarly, RALLY’s capacity-migration augmentation enables lightweight models to achieve comparable performance on resource-constrained platforms.

Convergent Findings
Despite heterogeneity, several findings converge across studies:

Hybrid architectures provide the best balance of coordination and scalability for most multi-robot scenarios.

Structured prompting with domain context (skill definitions, environmental constraints) consistently improves decomposition quality over generic prompting.

Integration of classical optimization with LLM reasoning (LiP-LLM, PLANTOR) achieves better allocation optimality than pure LLM approaches.

Feedback mechanisms are essential for maintaining performance in dynamic environments, with success rates dropping significantly without them.

Hardware constraint modeling depth correlates with allocation accuracy, particularly for heterogeneous teams.

References
Piyush Gupta, David Isele, Enna Sachdeva, Pin-Hao Huang, Behzad Dariush, and 2 more (2025). Generalized Mission Planning for Heterogeneous Multi-Robot Teams via LLM-Constructed Hierarchical Trees. IEEE International Conference on Robotics and Automation
Yongdong Wang, Runze Xiao, Junichi Kasahara, Ryosuke Yajima, Keiji Nagatani, and 2 more (2024). DART-LLM: Dependency-Aware Multi-Robot Task Decomposition and Execution using Large Language Models. arXiv.org
Kento Murata, Shoichi Hasegawa, Tomochika Ishikawa, Y. Hagiwara, Akira Taniguchi, and 2 more (2025). Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models. arXiv.org
S. Prieto, Borja García de Soto (2024). Large Language Models for Robot Task Allocation. IEEE International Conference on Robotics and Automation
Tinging Yang, Ping Feng, Qixin Guo, Jindi Zhang, Xiufeng Zhang, and 3 more (2025). AutoHMA-LLM: Efficient Task Coordination and Execution in Heterogeneous Multi-Agent Systems Using Hybrid Large Language Models. IEEE Transactions on Cognitive Communications and Networking
Yuxiao Zhu, Junfeng Chen, Xintong Zhang, Meng Guo, Zhongkui Li (2025). DEXTER-LLM: Dynamic and Explainable Coordination of Multi-Robot Systems in Unknown Environments via Large Language Models. arXiv.org
Alfonso Amayuelas, Jingbo Yang, Saaket Agashe, Ashwin Nagarajan, Antonis Antoniades, and 2 more (2025). Self-Resource Allocation in Multi-Agent LLM Systems. arXiv.org
S. S. Kannan, Vishnunandan L. N. Venkatesh, Byung-Cheol Min (2023). SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models. IEEE/RJS International Conference on Intelligent RObots and Systems
Kazuma Obata, Tatsuya Aoki, Takato Horii, Tadahiro Taniguchi, Takayuki Nagai (2024). LiP-LLM: Integrating Linear Programming and Dependency Graph With Large Language Models for Multi-Robot Task Planning. IEEE Robotics and Automation Letters
Csaba Hegedüs, Ádám Tóth, Máté Bancsics, Pál Varga (2025). Multi-Agentic Plan-and-Solve Engine for Managing System of Systems via Natural Language. IEEE/IFIP Network Operations and Management Symposium
Wentao Zhang, Ce Cui, Yilei Zhao, Rui Hu, Yang Liu, and 2 more (2025). AgentOrchestra: A Hierarchical Multi-Agent Framework for General-Purpose Task Solving. arXiv.org
Zhehui Huang, Guangyao Shi, Yuwei Wu, Vijay Kumar, Gaurav S. Sukhatme (2025). Compositional Coordination for Multi-Robot Teams with Large Language Models. arXiv.org
Zhirong Luan, Yujun Lai, Rundong Huang, Yan Yan, Jingwei Wang, and 2 more (2023). Hierarchical Large Language Models in Cloud-Edge-End Architecture for Heterogeneous Robot Cluster Control. ISCAI
Wenhao Yu, Jie Peng, Yueliang Ying, Sai Li, Jianmin Ji, and 1 more (2024). MHRC: Closed-loop Decentralized Multi-Heterogeneous Robot Collaboration with Large Language Models. arXiv.org
Marcos Abel Zuzu'arregui, Stefano Carpin (2025). Leveraging LLMs for Mission Planning in Precision Agriculture. IEEE International Conference on Robotics and Automation
Pranav Kak, Sushma Jain (2024). Embodied Reasoning with Self-Feedback. IEEE International Conference on Electronics, Computing and Communication Technologies
Kun Chu, Xufeng Zhao, C. Weber, Mengdi Li, Wenhao Lu, and 1 more (2024). Large Language Models for Orchestrating Bimanual Robots. IEEE-RAS International Conference on Humanoid Robots
Ji Zhao, Xiao Lin (2025). General-Purpose Aerial Intelligent Agents Empowered by Large Language Models. arXiv.org
Artem Lykov, Maria Dronova, Nikolay Naglov, Mikhail Litvinov, S. Satsevich, and 4 more (2023). LLM-MARS: Large Language Model for Behavior Tree Generation and NLP-enhanced Dialogue in Multi-Agent Robot Systems. arXiv.org
Andrea Tagliabue, Kota Kondo, Tong Zhao, Mason B. Peterson, Claudius T. Tewari, and 1 more (2023). REAL: Resilience and Adaptation using Large Language Models on Autonomous Aerial Robots. IEEE Conference on Decision and Control
J. Wang, J. Tong, Kai Liang Tan, Yevgeniy Vorobeychik, Y. Kantaros (2023). Conformal Temporal Logic Planning using Large Language Models. ACM Transactions on Cyber-Physical Systems
Jun Wang, Guocheng He, Y. Kantaros (2024). Safe Task Planning for Language-Instructed Multi-Robot Systems using Conformal Prediction. arXiv.org
Bin Zhang, Hangyu Mao, Jingqing Ruan, Ying Wen, Yang Li, and 7 more (2023). Controlling Large Language Model-based Agents for Large-Scale Decision-Making: An Actor-Critic Approach. arXiv.org
Ji Wang, Kashing Chen, Xinyuan Song, Ke Zhang, Lynn Ai, and 2 more (2025). Symphony: A Decentralized Multi-Agent Framework for Scalable Collective Intelligence
Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas Roy, Chuchu Fan (2023). Scalable Multi-Robot Collaboration with Large Language Models: Centralized or Decentralized Systems?. IEEE International Conference on Robotics and Automation
Jinqiang Cui, Guocai Liu, Hui Wang, Yue Yu, Jiankun Yang (2024). TPML: Task Planning for Multi-UAV System with Large Language Models. 2024 IEEE 18th International Conference on Control & Automation (ICCA)
Ishika Singh, Valts Blukis, A. Mousavian, Ankit Goyal, Danfei Xu, and 4 more (2022). ProgPrompt: Generating Situated Robot Task Plans using Large Language Models. IEEE International Conference on Robotics and Automation
Siddharth Nayak, Adelmo Morrison Orozco, M. T. Have, Vittal Thirumalai, Jackson Zhang, and 8 more (2024). Long-Horizon Planning for Multi-Agent Robots in Partially Observable Environments. Neural Information Processing Systems
Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, and 38 more (2022). Do As I Can, Not As I Say: Grounding Language in Robotic Affordances. Conference on Robot Learning
Hongxin Zhang, Weihua Du, Jiaming Shan, Qinhong Zhou, Yilun Du, and 3 more (2023). Building Cooperative Embodied Agents Modularly with Large Language Models. International Conference on Learning Representations
Xiaopan Zhang, Hao Qin, Fuquan Wang, Yue Dong, Jiachen Li (2024). LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner. IEEE International Conference on Robotics and Automation
Guangyao Chen, Siwei Dong, Yu Shu, Ge Zhang, Jaward Sesay, and 3 more (2023). AutoAgents: A Framework for Automatic Agent Generation. International Joint Conference on Artificial Intelligence
Silvia Izquierdo-Badiola, Gerard Canal, Carlos Rizzo, Guillem Alenyà (2024). PlanCollabNL: Leveraging Large Language Models for Adaptive Plan Generation in Human-Robot Collaboration. IEEE International Conference on Robotics and Automation
Marcos Abel Zuzu'arregui, Mustafa Melih Toslak, Stefano Carpin (2025). One For All: LLM-based Heterogeneous Mission Planning in Precision Agriculture. arXiv.org
Xiaonan Xu, Haoshuo Chen, Jesse E. Simsarian, R. Ryf, N. Fontaine, and 3 more (2024). Large Language Model-Driven Cross-Domain Orchestration Using Multi-Agent Workflow. arXiv.org
Junhong Chen, Ziqi Yang, Haoyuan G Xu, Dandan Zhang, George P. Mylonas (2025). Multi-Agent Systems for Robotic Autonomy with LLMs. 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)
Kartik Nagpal, Dayi Dong, Jean-Baptiste Bouvier, Negar Mehr (2025). Leveraging Large Language Models for Effective and Explainable Multi-Agent Credit Assignment. Adaptive Agents and Multi-Agent Systems
Hao Sha, Yao Mu, Yuxuan Jiang, Li Chen, Chenfeng Xu, and 5 more (2023). LanguageMPC: Large Language Models as Decision Makers for Autonomous Driving. arXiv.org
William Hunt, Toby Godfrey, Mohammad Divband Soorati (2024). Conversational Language Models for Human-in-the-Loop Multi-Robot Coordination. Adaptive Agents and Multi-Agent Systems
Jun Wang, Guocheng He, Y. Kantaros (2024). Probabilistically Correct Language-Based Multi-Robot Planning Using Conformal Prediction. IEEE Robotics and Automation Letters
Min Deng, Bo Fu, Lingyao Li, Xi Wang (2025). Integrating LLMs and Digital Twins for Adaptive Multi-Robot Task Allocation in Construction. arXiv.org
Anan Jin, Yuhang Ye, Brian Lee, Yansong Qiao (2024). DeCoAgent: Large Language Model Empowered Decentralized Autonomous Collaboration Agents Based on Smart Contracts. IEEE Access
Ashish Kumar (2025). Application of LLMs to Multi-Robot Path Planning and Task Allocation. arXiv.org
Arvind Car, Sai Sravan Yarlagadda, Alison Bartsch, Abraham George, A. Farimani (2024). PLATO: Planning with LLMs and Affordances for Tool Manipulation. arXiv.org
Kehui Liu, Zixin Tang, Dong Wang, Zhigang Wang, Bin Zhao, and 1 more (2024). COHERENT: Collaboration of Heterogeneous Multi-Robot System with Large Language Models. IEEE International Conference on Robotics and Automation
Hongwei Cui, Yuyang Du, Qun Yang, Yulin Shao, S. Liew (2023). LLMind: Orchestrating AI and IoT with LLM for Complex Task Execution. IEEE Communications Magazine
Zhaoxing Li, Wenbo Wu, Yue Wang, Yanran Xu, William Hunt, and 1 more (2025). HMCF: A Human-in-the-loop Multi-Robot Collaboration Framework Based on Large Language Models. arXiv.org
Yuchen Liu, Luigi Palmieri, Sebastian Koch, Ilche Georgievski, Marco Aiello (2024). DELTA: Decomposed Efficient Long-Term Robot Task Planning Using Large Language Models. IEEE International Conference on Robotics and Automation
David Maranto (2024). LLMSat: A Large Language Model-Based Goal-Oriented Agent for Autonomous Space Exploration. arXiv.org
Archiki Prasad, Alexander Koller, Mareike Hartmann, Peter Clark, Ashish Sabharwal, and 2 more (2023). ADaPT: As-Needed Decomposition and Planning with Language Models. NAACL-HLT
Mukund Mitra, Yashaswi Sinha, Arushi Khokhar, Sairam Jinkala, Pradipta Biswas (2025). LMD-FISH: Language Model Driven - Framework for Intelligent Scheduling of Heterogenous Systems. IUI Companion
Zhao Mandi, Shreeya Jain, Shuran Song (2023). RoCo: Dialectic Multi-Robot Collaboration with Large Language Models. IEEE International Conference on Robotics and Automation
Philipp Allgeuer, Hassan Ali, Stefan Wermter (2024). When Robots Get Chatty: Grounding Multimodal Human-Robot Conversation and Collaboration. International Conference on Artificial Neural Networks
Masoud Shokrnezhad, T. Taleb (2025). An Autonomous Network Orchestration Framework Integrating Large Language Models with Continual Reinforcement Learning. IEEE Communications Magazine
Jonghan Lim, Ilya Kovalenko (2025). Dynamic Task Adaptation for Multi-Robot Manufacturing Systems with Large Language Models. arXiv.org
Yi Wu, Zikang Xiong, Yiran Hu, Shreyash S. Iyengar, Nan Jiang, and 3 more (2024). SELP: Generating Safe and Efficient Task Plans for Robot Agents with Large Language Models. IEEE International Conference on Robotics and Automation
Yuchen Xia, Manthan Shenoy, N. Jazdi, M. Weyrich (2023). Towards autonomous system: flexible modular production system enhanced with large language model agents. IEEE International Conference on Emerging Technologies and Factory Automation
Zhiwei Liu, Weiran Yao, Jianguo Zhang, Le Xue, Shelby Heinecke, and 10 more (2023). BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents. arXiv.org
P. S. Reddy (2025). Multimodal LLM-Based Robotic System for Dynamic Task Execution and Human Interaction. International Journal for Research in Applied Science and Engineering Technology
Junda He, Christoph Treude, David Lo (2024). LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision, and the Road Ahead. ACM Transactions on Software Engineering and Methodology
Noel Crawford, Edward B. Duffy, Iman Evazzade, Torsten Foehr, Gregory Robbins, and 3 more (2024). BMW Agents - A Framework For Task Automation Through Multi-Agent Collaboration. arXiv.org
Mengdi Xu, Peide Huang, Wenhao Yu, Shiqi Liu, Xilun Zhang, and 5 more (2023). Creative Robot Tool Use with Large Language Models. arXiv.org
Prattyush Mangal, Carol Mak, Theo Kanakis, Timothy Donovan, Dave Braines, and 1 more (2024). Coalitions of Large Language Models Increase the Robustness of AI Agents. arXiv.org
Yongchao Chen, Jacob Arkin, Yang Zhang, Nicholas A. Roy, Chuchu Fan (2023). AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers. IEEE International Conference on Robotics and Automation
Alkesh K. Srivastava, Jared Michael Levin, Alexander Derrico, Philip Dames (2025). DELIVER: A System for LLM-Guided Coordinated Multi-Robot Pickup and Delivery using Voronoi-Based Relay Planning. arXiv.org
Ziyi Yang, S. S. Raman, Ankit Shah, Stefanie Tellex (2023). Plug in the Safety Chip: Enforcing Constraints for LLM-driven Robot Agents. IEEE International Conference on Robotics and Automation
Yufan Dang, Cheng Qian, Xueheng Luo, Jingru Fan, Zihao Xie, and 9 more (2025). Multi-Agent Collaboration via Evolving Orchestration. arXiv.org
Yutong Liu, Qingquan Sun, Dhruvi Kapadia (2025). Integrating Large Language Models into Robotic Autonomy: A Review of Motion, Voice, and Training Pipelines. Applied Informatics
Christina Sarkisyan, A. Korchemnyi, A. Kovalev, A. Panov (2023). Evaluation of Pretrained Large Language Models in Embodied Planning Tasks. Artificial General Intelligence
Swarnamouli Majumdar, Sonny E. Kirkley, Biswadip Basu Mallik (2025). LLM-Guided Hybrid Architecture for Autonomous Fire Response: Dialog-Driven Planning in Space and Disaster Missions. 2025 IEEE World AI IoT Congress (AIIoT)
Wenhao Yu, Nimrod Gileadi, Chuyuan Fu, Sean Kirmani, Kuang-Huei Lee, and 15 more (2023). Language to Rewards for Robotic Skill Synthesis. Conference on Robot Learning
Krishan Rana, Jesse Haviland, Sourav Garg, Jad Abou-Chakra, I. Reid, and 1 more (2023). SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Task Planning. Conference on Robot Learning
Yuyang Du, Qun Yang, Liujianfu Wang, Jingqi Lin, Hongwei Cui, and 1 more (2025). LLMind 2.0: Distributed IoT Automation with Natural Language M2M Communication and Lightweight LLM Agents. arXiv.org
Jinwei Su, Qizhen Lan, Yinghui Xia, Lifan Sun, Weiyou Tian, and 2 more (2025). Difficulty-Aware Agentic Orchestration for Query-Specific Multi-Agent Workflows
Elliot Meyerson, Xin Qiu (2025). Position: Scaling LLM Agents Requires Asymptotic Analysis with LLM Primitives. arXiv.org
Yutao Ouyang, Jinhan Li, Yunfei Li, Zhongyu Li, Chao Yu, and 2 more (2024). Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models. arXiv.org
Rui Yang, Rajiv Gupta (2025). DREAM: Distributed Regional Efficient Agent Management with LLMs for Online Multi-Agent Pathfinding. ACM SIGOPS Operating Systems Review
Huibo Zhang, Shengkang Chen, Huan Yin, Fumin Zhang (2024). An In-Context Learning Approach for LLM-Enabled Multi-Robot Task Allocation. IEEE International Conference on Robotics and Biomimetics
Huaben Chen, Wenkang Ji, Lufeng Xu, Shiyu Zhao (2023). Multi-Agent Consensus Seeking via Large Language Models. arXiv.org
Zhirong Luan, Yujun Lai, Rundong Huang, Shuanghao Bai, Yuedi Zhang, and 2 more (2024). Enhancing Robot Task Planning and Execution through Multi-Layer Large Language Models. Italian National Conference on Sensors
Tushar Chugh, Kanishka Tyagi, Pranesh Srinivasan, Jeshwanth Challagundla (2024). State-Based Dynamic Graph with Breadth First Progression For Autonomous Robots. Computing and Communication Workshop and Conference
Bo Ni, Markus J. Buehler (2023). MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge. arXiv.org
Chuanneng Sun, Songjun Huang, Haiqiao Liu, Jie Gong, D. Pompili (2024). Retrieval-Augmented Hierarchical in-Context Reinforcement Learning and Hindsight Modular Reflections for Task Planning with LLMs. IEEE International Conference on Robotics and Automation
Hong Cao, Rong Ma, Yanlong Zhai, Jun Shen (2024). LLM-Collab: a framework for enhancing task planning via chain-of-thought and multi-agent collaboration. Applied Computing and Intelligence
Manish Bhatt, Ronald F. Del Rosario, Vineeth Sai Narajala, Idan Habler (2025). COALESCE: Economic and Security Dynamics of Skill-Based Task Outsourcing Among Team of Autonomous LLM Agents. arXiv.org
Logan Cross, Violet Xiang, Agam Bhatia, Daniel L. K. Yamins, Nick Haber (2024). Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models. International Conference on Learning Representations
Fernando Cladera, Zachary Ravichandran, Jason Hughes, Varun Murali, Carlos Nieto-Granda, and 4 more (2025). Air-Ground Collaboration for Language-Specified Missions in Unknown Environments. IEEE Transactions on Field Robotics
Abhinav Rajvanshi, Pritish Sahu, Tixiao Shan, Karan Sikka, Han-Pang Chiu (2025). SayCoNav: Utilizing Large Language Models for Adaptive Collaboration in Decentralized Multi-Robot Navigation. arXiv.org
Sumedh Rasal, E. Hauer (2024). Navigating Complexity: Orchestrated Problem Solving with Multi-Agent LLMs. arXiv.org
Brian M. Robinson, Nathan Redmond, Zachary Adler, Robert A. Diltz (2025). Metric-semantic reasoning, tool calling, and NLP interfaces: using LLMs at the edge for human-robot teaming. Defense + Security
Yu Pan, Jianxin Sun, Hongfeng Yu, Joe D. Luck, Geng Bai, and 3 more (2024). Building Multi-Agent Copilot towards Autonomous Agricultural Data Management and Analysis. BigData Congress [Services Society]
Yongchang Li, Yajie Liu, Jie Ren, Yanzhi Dong (2024). Natural Language Navigation Task Allocation for Robot Based on Agents. 2024 9th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)
Xiaonan Xu, Haoshuo Chen, R. Ryf, S. Bidkar, J. Simsarian, and 6 more (2025). Cross-Domain Orchestration with Multi-Agent LLM Framework for Enhanced Task Automation. Optical Fiber Communications Conference and Exhibition
Yuwei Wu, Yuezhan Tao, Peihan Li, Guangyao Shi, Gaurav S. Sukhatme, and 2 more (2024). Hierarchical LLMs In-the-loop Optimization for Real-time Multi-Robot Target Tracking under Unknown Hazards. arXiv.org
Jason Liu, Ziyi Yang, Benjamin Schornstein, Sam Liang, Ifrah Idrees, and 2 more (2022). Lang2LTL: Translating Natural Language Commands to Temporal Specification with Large Language Models
Hao Wu, Huailin Zhao, Lumeng Ma, Yongchang Li, Cen Chen, and 1 more (2024). Task Allocation for Heterogeneous Robots in Office Environments Using Large Language Models. 2024 9th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS)
Eyal Klang, Mahmud Omar, Ganesh Raut, R. Agbareia, P. Timsina, and 6 more (2025). Orchestrated multi agents sustain accuracy under clinical-scale workloads compared to a single agent. medRxiv
Yang Yue, Yulin Wang, Bingyi Kang, Yizeng Han, Shenzhi Wang, and 3 more (2024). DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution. Neural Information Processing Systems
Jianliang He, Siyu Chen, Fengzhuo Zhang, Zhuoran Yang (2024). From Words to Actions: Unveiling the Theoretical Underpinnings of LLM-Driven Autonomous Systems. International Conference on Machine Learning
Jake Brawer, Kayleigh Bishop, Bradley Hayes, A. Roncone (2023). Towards A Natural Language Interface for Flexible Multi-Agent Task Assignment. Proceedings of the AAAI Symposium Series
Miguel Ángel González Santamarta, F. J. Rodríguez-Lera, Á. Guerrero-Higueras, Vicente Matellán Olivera (2023). Integration of Large Language Models within Cognitive Architectures for Autonomous Robots. arXiv.org
А. Р. Бідочко, Ярослав Виклюк (2025). LLMAGENTNET: A COLLABORATIVE NETWORK OF AUTONOMOUS AI AGENTS FOR COMPLEX TASK EXECUTION. Scientific Bulletin of UNFU
Zhirui Dai, Arash Asgharivaskasi, T. Duong, Shusen Lin, Maria-Elizabeth Tzes, and 2 more (2023). Optimal Scene Graph Planning with Large Language Model Guidance. IEEE International Conference on Robotics and Automation
Priyanshi saxena, Roshan Lal (2025). Leveraging Large Language Models in Multiagent System. International Journal For Multidisciplinary Research
Minseo Kwon, Yaesol Kim, Young J. Kim (2024). Fast and Accurate Task Planning using Neuro-Symbolic Language Models and Multi-Level Goal Decomposition. IEEE International Conference on Robotics and Automation
Enrico Saccon, Ahmet Tikna, Davide De Martini, Edoardo Lamon, Luigi Palopoli, and 1 more (2025). A Temporal Planning Framework for Multi-Agent Systems via LLM-Aided Knowledge Base Management. arXiv.org
Alejandro D. Mousist (2025). ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy. arXiv.org
Nicolas Baumann, Cheng Hu, Paviththiren Sivasothilingam, Haotong Qin, Lei Xie, and 2 more (2025). Enhancing Autonomous Driving Systems with On-Board Deployed Large Language Models. Robotics
Changxin Huang, Junyang Liang, Yanbin Chang, Jingzhao Xu, Jianqiang Li (2025). Automated Hybrid Reward Scheduling Via Large Language Models for Robotic Skill Learning. IEEE International Conference on Robotics and Automation
Zachary Ravichandran, Varun Murali, Mariliza Tzes, George J. Pappas, Vijay Kumar (2024). SPINE: Online Semantic Planning for Missions with Incomplete Natural Language Specifications in Unstructured Environments. IEEE International Conference on Robotics and Automation
Kaustubh Vyas, Damien Graux, Yijun Yang, Sébastien Montella, Chenxin Diao, and 6 more (2024). From An LLM Swarm To A PDDL-Empowered HIVE: Planning Self-Executed Instructions In A Multi-Modal Jungle. arXiv.org
Feipeng Ma, Yizhou Zhou, Yueyi Zhang, Siying Wu, Zheyu Zhang, and 3 more (2024). Task Navigator: Decomposing Complex Tasks for Multimodal Large Language Models. 2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)
Kaiwei Liu, Bufang Yang, Lilin Xu, Yunqi Guo, Guoliang Xing, and 4 more (2025). TaskSense: A Translation-like Approach for Tasking Heterogeneous Sensor Systems with LLMs. ACM International Conference on Embedded Networked Sensor Systems
Brennen Hill (2025). Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning
Saaduddin Mahmud, Dorian Benhamou Goldfajn, S. Zilberstein (2025). Distributed Multi-Agent Coordination Using Multi-Modal Foundation Models. arXiv.org
Harsh Singh, Rocktim Jyoti Das, Mingfei Han, Preslav Nakov, Ivan Laptev (2024). MALMM: Multi-Agent Large Language Models for Zero-Shot Robotics Manipulation. arXiv.org
Dan BW Choe, Sundhar Vinodh Sangeetha, Steven Emanuel, Chih-Yuan Chiu, Samuel Coogan, and 1 more (2025). Seeing, Saying, Solving: An LLM-to-TL Framework for Cooperative Robots. arXiv.org
Zhengyi Cheng, Chongxi Ma, Mingxuan Tang, Jie Xu, Quan Li, and 2 more (2025). Poster: LLM Multi-Agent Collaboration for Network Deployment and Management. IEEE International Conference on Network Protocols
Michele Brienza, Emanuele Musumeci, Vincenzo Suriani, Daniele Affinita, A. Pennisi, and 2 more (2024). LLCoach: Generating Robot Soccer Plans using Multi-Role Large Language Models. Robot Soccer World Cup
Marc Glocker, Peter Hönig, Matthias Hirschmanner, Markus Vincze (2025). LLM-Empowered Embodied Agent for Memory-Augmented Task Planning in Household Robotics. arXiv.org
Ruochu Yang, Mengxue Hou, Junkai Wang, Fumin Zhang (2023). OceanChat: Piloting Autonomous Underwater Vehicles in Natural Language. arXiv.org
Xihe Qiu, Haoyu Wang, Xiaoyu Tan, Chao Qu (2024). ILTS: Inducing Intention Propagation in Decentralized Multi-Agent Tasks with Large Language Models. International Conference on Information and Knowledge Management
Venkata Naren Devarakonda, Raktim Gautam Goswami, Ali Umut Kaypak, Naman Patel, Rooholla Khorrambakht, and 2 more (2024). OrionNav: Online Planning for Robot Autonomy with Context-Aware LLM and Open-Vocabulary Semantic Scene Graphs. arXiv.org
Kolby Nottingham, Prithviraj Ammanabrolu, Alane Suhr, Yejin Choi, Hannaneh Hajishirzi, and 2 more (2023). Do Embodied Agents Dream of Pixelated Sheep?: Embodied Decision Making using Language Guided World Modelling. International Conference on Machine Learning
Chuanhong Fang, X. Yue, Zhendong Zhao, Shijie Guo (2025). The Multi-Agentization of a Dual-Arm Nursing Robot Based on Large Language Models. Bioengineering
Yash Shukla, Wenchang Gao, Vasanth Sarathy, Alvaro Velasquez, Robert Wright, and 1 more (2023). LgTS: Dynamic Task Sampling using LLM-generated sub-goals for Reinforcement Learning Agents. Adaptive Agents and Multi-Agent Systems
Tao Song, Man Luo, Xiaolong Zhang, Linjiang Chen, Yan Huang, and 11 more (2025). A Multiagent-Driven Robotic AI Chemist Enabling Autonomous Chemical Research On Demand. Journal of the American Chemical Society
Bin Hu, Chenyang Zhao, Pushi Zhang, Zihao Zhou, Yuanhang Yang, and 2 more (2023). Enabling Intelligent Interactions between an Agent and an LLM: A Reinforcement Learning Approach. RLJ
Oleg Sautenkov, Yasheerah Yaqoot, Muhammad Ahsan Mustafa, Faryal Batool, Jeffrin Sam, and 3 more (2025). UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning. arXiv.org
Ziyao Wang, Rongpeng Li, Sizhao Li, Yuming Xiang, Haiping Wang, and 2 more (2025). RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms. arXiv.org
Saeed Hubairik Aliyu, Victor Adedeji Tobiloba, Hamzat Toheeb Adekunle, Hanafi Musa Olayinka, Kalu Grace Onuma, and 2 more (2025). Integrating Large Language Models in Robotics to Empower Autonomous Agents with Natural Language Comprehension Capabilities: A Comprehensive Review. International Journal of Future Engineering Innovations
Lingfeng Sun, Devesh K. Jha, Chiori Hori, Siddarth Jain, Radu Corcodel, and 3 more (2023). Interactive Planning Using Large Language Models for Partially Observable Robotic Tasks. IEEE International Conference on Robotics and Automation
Qingyang Zhang, Fumio Machida (2025). AI Agent-based Adaptive Task Offloading for Autonomous Drones in Dynamic Environments. 2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S)
Ishika Singh, David Traum, Jesse Thomason (2024). TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models. arXiv.org
Vladimir Berman, Artem Bazhenov, Dzmitry Tsetserukou (2024). MissionGPT: Mission Planner for Mobile Robot based on Robotics Transformer Model. 2024 2nd International Conference on Foundation and Large Language Models (FLLM)
Mozhgan Navardi, Shang Gao, Mikolaj Walczak, Fernando Camacho, T. Mohsenin (2025). Metareasoning for Edge-Cloud Collaborative LLM Planning for Efficient Autonomous Navigation. ACM Transactions on Embedded Computing Systems
Peihan Li, Lifeng Zhou (2025). LLM-Flock: Decentralized Multi-Robot Flocking via Large Language Models and Influence-Based Consensus. arXiv.org
Guibin Zhang, Yanwei Yue, Xiangguo Sun, Guancheng Wan, Miao Yu, and 3 more (2024). G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks. arXiv.org
Yan Ding, Xiaohan Zhang, Chris Paxton, Shiqi Zhang (2023). Task and Motion Planning with Large Language Models for Object Rearrangement. IEEE/RJS International Conference on Intelligent RObots and Systems
Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, and 2 more (2023). Theory of Mind for Multi-Agent Collaboration via Large Language Models. Conference on Empirical Methods in Natural Language Processing
Jinjie Mai, Jun Chen, Bing-chuan Li, Guocheng Qian, Mohamed Elhoseiny, and 1 more (2023). LLM as A Robotic Brain: Unifying Egocentric Memory and Control. arXiv.org
N. Nascimento, Paulo Alencar, Donald D. Cowan (2023). Self-Adaptive Large Language Model (LLM)-Based Multiagent Systems. 2023 IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion (ACSOS-C)
Attique Bashir, Raja Moktafi, Marco Giangreco, Rainer Müller (2024). State Space Exploration with Large Language Models for Human-Robot Cooperation in Mechanical Assembly. ROBOT
Vasili Braga (2023). DECENTRALISED AUTONOMOUS SOCIETY THROUGH LARGE LANGUAGE MODELS’ BASED AGENTS: A PATHWAY TO EMPOWER SMALL COMMUNITIES. Journal of Engineering Science
Tianshun Lin, Changgui Xu, Jianshan Zhang, Nan Lin, Yuxin Liu, and 1 more (2025). Leveraging Large Language Models for Network Security: A Multi‐Expert Approach. Internet Technology Letters
Chao Wang, Stephan Hasler, Daniel Tanneberg, Felix Ocker, F. Joublin, and 3 more (2024). LaMI: Large Language Models for Multi-Modal Human-Robot Interaction. CHI Extended Abstracts
Ishita Dasgupta, Christine Kaeser-Chen, Kenneth Marino, Arun Ahuja, Sheila Babayan, and 2 more (2023). Collaborating with language models for embodied reasoning. arXiv.org
Yi Zheng, Chongyang Ma, Kanle Shi, Haibin Huang (2023). Agents meet OKR: An Object and Key Results Driven Agent System with Hierarchical Self-Collaboration and Self-Evaluation. arXiv.org
Hsu-Shen Liu, So Kuroki, Tadashi Kozuno, Wei-Fang Sun, Chun-Yi Lee (2024). Language-Guided Pattern Formation for Swarm Robotics with Multi-Agent Reinforcement Learning. IEEE/RJS International Conference on Intelligent RObots and Systems
Victor de Lamo Castrillo, Habtom Kahsay Gidey, Alexander Lenz, Alois Knoll (2025). Fundamentals of Building Autonomous LLM Agents
Michael Ahn, Debidatta Dwibedi, Chelsea Finn, Montse Gonzalez Arenas, K. Gopalakrishnan, and 22 more (2024). AutoRT: Embodied Foundation Models for Large Scale Orchestration of Robotic Agents. arXiv.org
Zain Asgar, Michelle Nguyen, Sachin Katti (2025). Efficient and Scalable Agentic AI with Heterogeneous Systems. arXiv.org
Chak Lam Shek, Pratap Tokekar (2025). Option Discovery Using LLM-guided Semantic Hierarchical Reinforcement Learning. arXiv.org
Ronghao Xu, Ke Huang, Ming Li, Yanyu Zhang, Lili Zhang, and 2 more (2025). Task Planning for Embodied Intelligent Robots. 2025 International Conference on Mechatronics, Robotics, and Artificial Intelligence (MRAI)
Miguel Ángel González Santamarta, Laura Fernández-Becerra, David Sobrín-Hidalgo, Á. Guerrero-Higueras, Irene Gonz'alez, and 1 more (2023). Using Large Language Models for Interpreting Autonomous Robots Behaviors. Hybrid Artificial Intelligence Systems
James R. Kirk, R. Wray, Peter Lindes (2023). Improving Knowledge Extraction from LLMs for Robotic Task Learning through Agent Analysis. arXiv.org
Zhuoran Xiao, Chenhui Ye, Yunbo Hu, Honggang Yuan, Yihang Huang, and 3 more (2024). LLM Agents as 6G Orchestrator: A Paradigm for Task-Oriented Physical-Layer Automation. 2024 IEEE Globecom Workshops (GC Wkshps)
Jian Wang, Guangtao Fu, Dragan A. Savić (2025). Leveraging large language models for automating water distribution network optimization. Water Research
Sahar Salimpour, Leijie Fu, Farhad Keramat, L. Militano, G. T. Carughi, and 2 more (2025). Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction. arXiv.org
Arpan Shaileshbhai Korat (2025). Synergistic minds: A collaborative multi-agent framework for integrated AI tool development using diverse large language models. World Journal of Advanced Research and Reviews
Mengkang Hu, Yuhang Zhou, Wendong Fan, Yuzhou Nie, Bowei Xia, and 11 more (2025). OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation. arXiv.org
Kaveesha Samarathunga, Ranuri Gurusinghe, Kugesan Sivasothynathan, C. Wanigasekara, Jason Mars, and 1 more (2025). LLM-Guided Multi-Agent System for Natural Language-Based Robot Navigation. 2025 IEEE World AI IoT Congress (AIIoT)
Alvin Zhu, Yusuke Tanaka, Andrew Goldberg, Dennis W. Hong (2025). AURA: Autonomous Upskilling with Retrieval-Augmented Agents
Peihan Li, Zijian An, Shams Abrar, Lifeng Zhou (2025). Large Language Models for Multi-Robot Systems: A Survey. arXiv.org
Jin Wang, Nikos Tsagarakis (2024). Grounding Language Models in Autonomous Loco-manipulation Tasks. arXiv.org
Junting Chen, Checheng Yu, Xunzhe Zhou, Tianqi Xu, Yao Mu, and 5 more (2024). EMOS: Embodiment-aware Heterogeneous Multi-robot Operating System with LLM Agents. International Conference on Learning Representations
Seif Ismail, Antonio Arbues, Ryan Cotterell, René Zurbrügg, Carmen Amo Alonso (2024). NARRATE: Versatile Language Architecture for Optimal Control in Robotics. IEEE/RJS International Conference on Intelligent RObots and Systems
Himanshu Pandey, Akhil Amod, Shivang Kumar (2024). Advancing Healthcare Automation: Multi-Agent System for Medical Necessity Justification. Workshop on Biomedical Natural Language Processing
Tengchao Zhang, Yonglin Tian, Fei Lin, Jun Huang, Patrik P. Süli, and 2 more (2025). CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios. arXiv.org
Muhayy ud Din, Waseem Akram, A. B. Bakht, Yihao Dong, Irfan Hussain (2025). Maritime Mission Planning for Unmanned Surface Vessel using Large Language Model. Simulation, Modeling, and Programming for Autonomous Robots
Yingxuan Yang, Huacan Chai, Shuai Shao, Yuanyi Song, Siyuan Qi, and 2 more (2025). AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems. arXiv.org
Georgia Chalvatzaki, A. Younes, Daljeet Nandha, An T. Le, Leonardo F. R. Ribeiro, and 1 more (2023). Learning to reason over scene graphs: a case study of finetuning GPT-2 into a robot language model for grounded task planning. Frontiers Robotics AI
Cong Zhang, Derrick-Goh-Xin Deik, Dexun Li, Hao Zhang, Yong Liu (2024). Planning with Multi-Constraints via Collaborative Language Agents. International Conference on Computational Linguistics
Victor Molina, Oriol Ruiz-Celada, Raúl Suárez, Jan Rosell, Isiah Zaplana (2025). Robot Situation and Task Awareness Using Large Language Models and Ontologies. 2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)
Siyuan Huang, Zhengkai Jiang, Hao Dong, Y. Qiao, Peng Gao, and 1 more (2023). Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model. arXiv.org
Xihe Qiu, Haoyu Wang, Xiaoyu Tan, Chao Qu, Yujie Xiong, and 4 more (2024). Towards Collaborative Intelligence: Propagating Intentions and Reasoning for Multi-Agent Coordination with Large Language Models. arXiv.org
Jordán Pascual Espada, Sofia Yiyu Qiu, R. G. Crespo, Juan Luis Carús (2025). Leveraging large language models for autonomous robotic mapping and navigation. International Journal of Advanced Robotic Systems
Ishika Singh, Valts Blukis, A. Mousavian, Ankit Goyal, Danfei Xu, and 4 more (2023). ProgPrompt: program generation for situated robot task planning using large language models. Autonomous Robots
Haoyu Zhou, Mingyu Ding, Weikun Peng, Masayoshi Tomizuka, Lin Shao, and 1 more (2023). Generalizable Long-Horizon Manipulations with Large Language Models. arXiv.org
Ziqi Jia, Junjie Li, Xiaoyang Qu, Jianzong Wang (2025). Enhancing Multi-Agent Systems via Reinforcement Learning with LLM-Based Planner and Graph-Based Policy. IEEE International Conference on Robotics and Automation
Younes Lakhnati, Max Pascher, Jens Gerken (2023). Exploring Large Language Models to Facilitate Variable Autonomy for Human-Robot Teaming. arXiv.org
Guojun Chen, Xiaojing Yu, Lin Zhong (2023). TypeFly: Flying Drones with Large Language Model. arXiv.org
Runjia Tan, Shanhe Lou, Yanxin Zhou, Chen Lv (2024). Multi-modal LLM-enabled Long-horizon Skill Learning for Robotic Manipulation. 2024 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE International Conference on Robotics, Automation and Mechatronics (RAM)
Shiyuan Li, Yixin Liu, Qingsong Wen, Chengqi Zhang, Shirui Pan (2025). Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation. arXiv.org
Binsheng Feng, Zhigang Wang, Xianzhong Dai (2024). Task Planning for Dual-Arm Robot Empowered by Large Language Model. ACM Cloud and Autonomic Computing Conference
Kanghyun Ryu, Qiayuan Liao, Zhongyu Li, K. Sreenath, Negar Mehr (2024). CurricuLLM: Automatic Task Curricula Design for Learning Complex Robot Skills Using Large Language Models. IEEE International Conference on Robotics and Automation
Patara Trirat, Wonyong Jeong, Sung Ju Hwang (2024). AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML. arXiv.org
Haolin Li, Peng Yi, Dixiao Wei, Wenyan Bai (2024). Seek-and-Take Games of Heterogeneous Agent Teams with Large Language Model. ACM Cloud and Autonomic Computing Conference
Chenyang Shao, Xinyang Liu, Yutang Lin, Fengli Xu, Yong Li (2025). Route-and-Reason: Scaling Large Language Model Reasoning with Reinforced Model Router. arXiv.org
Andy Zeng, Brian Ichter, Fei Xia, Ted Xiao, Vikas Sindhwani (2023). Demonstrating Large Language Models on Robots. Robotics: Science and Systems
Yongliang Shen, Kaitao Song, Xu Tan, Wenqi Zhang, Kan Ren, and 4 more (2023). TaskBench: Benchmarking Large Language Models for Task Automation. Neural Information Processing Systems
Harisankar Babu, Philipp Schillinger, Tamim Asfour (2025). Adaptive Domain Modeling with Language Models: A Multi-Agent Approach to Task Planning. 2025 IEEE 21st International Conference on Automation Science and Engineering (CASE)
Shaojun Xu, Xusheng Luo, Yutong Huang, Letian Leng, Ruixuan Liu, and 1 more (2024). Nl2Hltl2Plan: Scaling Up Natural Language Understanding for Multi-Robots Through Hierarchical Temporal Logic Task Specifications. IEEE Robotics and Automation Letters
Miguel 'A. Gonz'alez-Santamarta, Irene Gonz'alez-Fern'andez, Francisco J. Rodr'iguez-Lera, 'Angel Manuel Guerrero-Higueras, Vicente Matell'an-Olivera (2023). Integration of Large Language Models within Cognitive Architectures for Autonomous Robots
Xiangkun Deng, Gang Tao, Chenxu Wen, Xi Zhang, Zhiyang Ju, and 1 more (2025). GMATP-LLM: A General Multi-Agent Task Dynamic Planning Method using Large Language Models. Cybersecurity and Cyberforensics Conference
Shuai Jia, Zhe Cui, Kai Wang, Yujie Ding, Dongming Han, and 1 more (2024). Adversarial and Cooperation Tasks in Multi- Agent System with Large Language Models. 2024 IEEE International Conference on Unmanned Systems (ICUS)
Maryam Hashemzadeh, Elias Stengel-Eskin, Sarath Chandar, Marc-Alexandre Côté (2024). Sub-goal Distillation: A Method to Improve Small Language Agents. CoLLAs
Chaojia Yu, Zihan Cheng, Hanwen Cui, Yishuo Gao, Zexu Luo, and 3 more (2025). A Survey on Agent Workflow – Status and Future. 2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD)
Yue Meng, Fei Chen, Yongchao Chen, Chuchu Fan (2025). AuDeRe: Automated Strategy Decision and Realization in Robot Planning and Control via LLMs. arXiv.org
Yotam Wolf, Binyamin Rothberg, Dorin Shteyman, A. Shashua (2024). Compositional Hardness of Code in Large Language Models - A Probabilistic Perspective. arXiv.org
Tianyu Wang, Yifan Li, Haitao Lin, Xiangyang Xue, Yanwei Fu (2023). WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model. arXiv.org
Talha Zeeshan, Abhishek Kumar, Susanna Pirttikangas, Sasu Tarkoma (2025). Large Language Model Based Multi-Agent System Augmented Complex Event Processing Pipeline for Internet of Multimedia Things. arXiv.org
Zhixun Chen, Yali Du, D. Mguni (2024). All Language Models Large and Small. arXiv.org
Zhehua Zhou, Jiayang Song, Kunpeng Yao, Zhan Shu, Lei Ma (2023). ISR-LLM: Iterative Self-Refined Large Language Model for Long-Horizon Sequential Task Planning. IEEE International Conference on Robotics and Automation
Xu Yang, Chenhui Lin, Yuelin Yang, Qi Wang, Hao Liu, and 2 more (2025). Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems. IEEE Transactions on Smart Grid
Minfeng Qi, Tianqing Zhu, Lefeng Zhang, Ningran Li, Wanlei Zhou (2025). Towards Transparent and Incentive-Compatible Collaboration in Decentralized LLM Multi-Agent Systems: A Blockchain-Driven Approach. arXiv.org
Shiva Sai Krishna Anand Tokal, Vaibhav Jha, Anand Eswaran, Praveen Jayachandran, Yogesh L. Simmhan (2025). Towards Orchestrating Agentic Applications as FaaS Workflows. IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum
Aoran Jiao, Tanmay P. Patel, Sanjmi Khurana, Anna-Mariya Korol, Lukas Brunke, and 4 more (2023). Swarm-GPT: Combining Large Language Models with Safe Motion Planning for Robot Choreography Design. arXiv.org
Yi Yang, Qingwen Zhang, Ci Li, Daniel Simoes Marta, Nazre Batool, and 1 more (2023). Human-Centric Autonomous Systems With LLMs for User Command Reasoning. 2024 IEEE/CVF Winter Conference on Applications of Computer Vision Workshops (WACVW)
Zhengdong Lu, Weikai Lu, Yiling Tao, Yun Dai, ZiXuan Chen, and 4 more (2025). Decompose, Plan in Parallel, and Merge: A Novel Paradigm for Large Language Models based Planning with Multiple Constraints. arXiv.org
Chaehong Lee, Varatheepan Paramanayakam, Andreas Karatzas, Yanan Jian, Michael Fore, and 5 more (2025). Multi-Agent Geospatial Copilots for Remote Sensing Workflows. arXiv.org
Nishanth Kumar, Fabio Ramos, Dieter Fox, Caelan Reed Garrett (2024). Open-World Task and Motion Planning via Vision-Language Model Inferred Constraints. arXiv.org
Abhinav Rajvanshi, Karan Sikka, Xiao Lin, Bhoram Lee, Han-Pang Chiu, and 1 more (2023). SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments. International Conference on Automated Planning and Scheduling
Pengying Wu, Yao Mu, Kangjie Zhou, Ji Ma, Junting Chen, and 1 more (2024). CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based Conversations. arXiv.org
Christos Chronis, Iraklis Varlamis, Dimitrios Michail, Konstantinos Tserpes, G. Dimitrakopoulos (2024). From Perception to Action: Leveraging LLMs and Scene Graphs for Intuitive Robotic Task Execution. International Conference on Big Data Computing Service and Applications
Zhizheng Zhang, Xiaoyi Zhang, Wenxuan Xie, Yan Lu (2023). Responsible Task Automation: Empowering Large Language Models as Responsible Task Automators. arXiv.org
Sadia Sultana Chowa, Riasad Alvi, Subhey Sadi Rahman, Md. Abdur Rahman, Mohaimenul Azam Khan Raiaan, and 3 more (2025). From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users
Mingchen Zhuge, Wenyi Wang, Louis Kirsch, Francesco Faccio, Dmitrii Khizbullin, and 1 more (2024). Language Agents as Optimizable Graphs. International Conference on Machine Learning
Luca Collini, Baleegh Ahmad, Joey Ah-kiow, Ramesh Karri (2025). MARVEL: Multi-Agent RTL Vulnerability Extraction using Large Language Models. arXiv.org
Adrian Garret Gabriel, Alaa Alameer Ahmad, Shankar Kumar Jeyakumar (2024). Advancing Agentic Systems: Dynamic Task Decomposition, Tool Integration and Evaluation using Novel Metrics and Dataset. arXiv.org
Simone Colombani, Dimitri Ognibene, Giuseppe Boccignone (2024). One to rule them all: natural language to bind communication, perception and action. AI4CC-IPS-RCRA-SPIRIT@AI*IA
Haotian Zhou, Yunhan Lin, Longwu Yan, Jihong Zhu, Huasong Min (2024). LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees. IEEE International Conference on Robotics and Automation
Guobin Zhu, Rui Zhou, Wenkang Ji, Shiyu Zhao (2025). LAMARL: LLM-Aided Multi-Agent Reinforcement Learning for Cooperative Policy Generation. IEEE Robotics and Automation Letters
Dimitrios Panagopoulos, Adolfo Perrusquía, Weisi Guo (2024). Selective Exploration and Information Gathering in Search and Rescue Using Hierarchical Learning Guided by Natural Language Input. IEEE International Conference on Systems, Man and Cybernetics
Neiwen Ling, Guojun Chen, Lin Zhong (2024). TimelyLLM: Segmented LLM Serving System for Time-sensitive Robotic Applications. arXiv.org
Zelong Li, Shuyuan Xu, Kai Mei, Wenyue Hua, Balaji Rama, and 4 more (2024). AutoFlow: Automated Workflow Generation for Large Language Model Agents. arXiv.org
Samuele Marro, Emanuele La Malfa, Jesse Wright, Guohao Li, Nigel Shadbolt, and 2 more (2024). A Scalable Communication Protocol for Networks of Large Language Models. arXiv.org
Hengjia Xiao, Peng Wang (2023). LLM A*: Human in the Loop Large Language Models Enabled A* Search for Robotics. arXiv.org
Mingming Peng, Zhendong Chen, Jie Yang, Jin Huang, Zhengqi Shi, and 3 more (2025). Automatic MILP Model Construction for Multi-Robot Task Allocation and Scheduling Based on Large Language Models. arXiv.org
Huangyuan Su, Aaron Walsman, Daniel Garces, S. Kakade, Stephanie Gil (2025). Data-Efficient Multi-Agent Spatial Planning with LLMs. arXiv.org
Kaushik Kannan, Jungyun Bae (2025). MTU-LLM: LLM-based Multi-Robot Task Allocation and Path Planning for Heterogeneous Robots in Search and Rescue Operations. AI Computer Science and Robotics Technology
Steven D. Morad, Ajay Shankar, Jan Blumenkamp, Amanda Prorok (2024). Language-Conditioned Offline RL for Multi-Robot Navigation. IEEE International Conference on Robotics and Automation
Jonathan Salfity, Selma Wanna, Minkyu Choi, Mitch Pryor (2024). Temporal and Semantic Evaluation Metrics for Foundation Models in Post-Hoc Analysis of Robotic Sub-tasks. arXiv.org
F. Joublin, Antonello Ceravola, Pavel Smirnov, Felix Ocker, Joerg Deigmoeller, and 5 more (2023). CoPAL: Corrective Planning of Robot Actions with Large Language Models. IEEE International Conference on Robotics and Automation
Abdelhaleem Saad, Waseem Akram, Irfan Hussain (2025). AquaChat++: LLM-Assisted Multi-ROV Inspection for Aquaculture Net Pens with Integrated Battery Management and Thruster Fault Tolerance. arXiv.org
Junyang Cai, Serdar Kadıoğlu, B. Dilkina (2025). Global Constraint LLM Agents for Text-to-Model Translation
Minghong Geng, Shubham Pateria, Budhitama Subagdja, Lin Li, Xin Zhao, and 1 more (2025). L2M2: A Hierarchical Framework Integrating Large Language Model and Multi-agent Reinforcement Learning. International Joint Conference on Artificial Intelligence
Haokun Liu, Zhaoqi Ma, Yunong Li, Junichiro Sugihara, Yicheng Chen, and 2 more (2025). Hierarchical Language Models for Semantic Navigation and Manipulation in an Aerial-Ground Robotic System. arXiv.org
Rongyu Zhang, Menghang Dong, Yuan Zhang, Liang Heng, Xiaowei Chi, and 5 more (2025). MoLe-VLA: Dynamic Layer-skipping Vision Language Action Model via Mixture-of-Layers for Efficient Robot Manipulation. arXiv.org
Wonje Choi, Woo Kyung Kim, Minjong Yoo, Honguk Woo (2024). Embodied CoT Distillation From LLM To Off-the-shelf Agents. International Conference on Machine Learning
Gui-Min Zhang, Luyang Niu, Junfeng Fang, Kun Wang, Lei Bai, and 1 more (2025). Multi-agent Architecture Search via Agentic Supernet. arXiv.org
Changhe Chen, Xiaohao Xu, Xiangdong Wang, Xiaonan Huang (2025). Large Language Models as Natural Selector for Embodied Soft Robot Design. arXiv.org
Yue Cao, C. S. Lee (2023). Ground Manipulator Primitive Tasks to Executable Actions using Large Language Models. Proceedings of the AAAI Symposium Series
J. Styrud, Matteo Iovino, Mikael Norrlöf, Mårten Björkman, Christian Smith (2024). Automatic Behavior Tree Expansion with LLMs for Robotic Manipulation. IEEE International Conference on Robotics and Automation
Seyed Hossein Ahmadpanah (2025). Semantic-Aware LLM Orchestration for Proactive Resource Management in Predictive Digital Twin Vehicular Networks. arXiv.org
Volker Strobel, Marco Dorigo, Mario Fritz (2024). LLM2Swarm: Robot Swarms that Responsively Reason, Plan, and Collaborate through LLMs. arXiv.org
Jingqing Ruan, Yihong Chen, Bin Zhang, Zhiwei Xu, Tianpeng Bao, and 5 more (2023). TPTU: Large Language Model-based AI Agents for Task Planning and Tool Usage
Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, and 3 more (2023). Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents. arXiv.org
Yibo Qiu, Zan Huang, Zhiyu Wang, Handi Liu, Yiling Qiao, and 5 more (2025). BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments. arXiv.org
Jonghan Lim, Birgit Vogel-Heuser, Ilya Kovalenko (2024). Large Language Model-Enabled Multi-Agent Manufacturing Systems. 2024 IEEE 20th International Conference on Automation Science and Engineering (CASE)
Alejandro Carrasco, Marco Nedungadi, E. Zucchelli, Amit Jain, Víctor Rodríguez-Fernández, and 1 more (2025). Visual Language Models as Operator Agents in the Space Domain. AIAA SCITECH 2025 Forum
Guangran Cheng, Chuheng Zhang, Wenzhe Cai, Li Zhao, Changyin Sun, and 1 more (2024). Empowering Large Language Models on Robotic Manipulation with Affordance Prompting. arXiv.org
Corban Rivera, Grayson Byrd, William Paul, Tyler Feldman, Meghan Booker, and 10 more (2024). ConceptAgent: LLM-Driven Precondition Grounding and Tree Search for Robust Task Planning and Execution. IEEE International Conference on Robotics and Automation
Chaoran Wang, Jingyuan Sun, Yanhui Zhang, Mingyu Zhang, C. Wu (2025). LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots
Wen Zhao, Liqiao Li, Hanwen Zhan, Yingqi Wang, Yiqi Fu (2024). Applying Large Language Model to a Control System for Multi-Robot Task Assignment. Drones
Shayan Meshkat Alsadat, Zhe Xu (2025). Large Language Model-Based Task Learning for Swarm Systems in Reinforcement Learning with Reward Machines. 2025 5th International Conference on Computer, Control and Robotics (ICCCR)
Zhe Ni, Xiao-Xin Deng, Cong Tai, Xin-Yue Zhu, Xiang Wu, and 2 more (2023). GRID: Scene-Graph-based Instruction-driven Robotic Task Planning. IEEE/RJS International Conference on Intelligent RObots and Systems
Zhenkun Li, Lingyao Li, Shuhang Lin, Yongfeng Zhang (2025). Know the Ropes: A Heuristic Strategy for LLM-based Multi-Agent System Design. arXiv.org
Yiming Xiong, Jian Wang, Bing Li, Yuhan Zhu, Yuqi Zhao (2025). Self-Organizing Agent Network for LLM-based Workflow Automation. arXiv.org
Zhipeng Hou, Junyi Tang, Yipeng Wang (2025). HALO: Hierarchical Autonomous Logic-Oriented Orchestration for Multi-Agent LLM Systems. arXiv.org
E. O. Badmus, Peng Sang, Dimitrios Stamoulis, Amritanshu Pandey (2025). PowerChain: Automating Distribution Grid Analysis with Agentic AI Workflows. arXiv.org
Jungkyoo Shin, Jieun Han, SeungJun Kim, Yoonseon Oh, Eunwoo Kim (2024). Task Planning for Long-Horizon Cooking Tasks Based on Large Language Models. IEEE/RJS International Conference on Intelligent RObots and Systems
Anlong Zhang, Jianmin Ji (2025). Leveraging Large Language Models for Modular Robot Navigation. 2025 4th International Symposium on Robotics, Artificial Intelligence and Information Engineering (RAIIE)
Sadra Zargarzadeh, Maryam Mirzaei, Yafei Ou, Mahdi Tavakoli (2024). From Decision to Action in Surgical Autonomy: Multi-Modal Large Language Models for Robot-Assisted Blood Suction. IEEE Robotics and Automation Letters
Xinzhu Liu, Peiyan Li, Wenju Yang, Di Guo, Huaping Liu (2024). Leveraging Large Language Model for Heterogeneous Ad Hoc Teamwork Collaboration. Robotics: Science and Systems
Bin Hu, Chenyang Zhao, Pushi Zhang, Zihao Zhou, Yuanhang Yang, and 2 more (2023). Enabling Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning Approach
Meghan Booker, Grayson Byrd, Bethany Kemp, Aurora Schmidt, Corban Rivera (2024). EmbodiedRAG: Dynamic 3D Scene Graph Retrieval for Efficient and Scalable Robot Task Planning. arXiv.org
Nan Li, Jiming Ren, Haris Miller, Samuel Coogan, K. Feigh, and 1 more (2025). Adaptive Obstacle-Aware Task Assignment and Planning for Heterogeneous Robot Teaming
Alexander Sommer, Peter Bazan, Behnam Babaeian, Jonathan Fellerer, Warren B. Powell, and 1 more (2025). Adaptive Self-Improvement for Smarter Energy Systems using Agentic Policy Search
Wanming Yu, Adrian Rofer, Abhinav Valada, S. Vijayakumar (2025). Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models
Shijun Xiao, Xinyuan Shi, Teng Chen, Yifan Zhang, Xuewen Rong, and 1 more (2025). Autonomous Behavior Control for Quadruped Robots with Arms Based on MultiModal Large Language Model. 2025 5th International Conference on Computer, Control and Robotics (ICCCR)
Yaran Chen, Wenbo Cui, Yuanwen Chen, Mining Tan, Xinyao Zhang, and 2 more (2023). RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks. arXiv.org
A. Khan, Michael Andrev, M. Murtaza, Sergio Aguilera, Rui Zhang, and 3 more (2025). Safety Aware Task Planning via Large Language Models in Robotics. arXiv.org
Yaran Chen, Wenbo Cui, Yuanwen Chen, Mining Tan, Xinyao Zhang, and 4 more (2025). RoboGPT: An LLM-Based Long-Term Decision-Making Embodied Agent for Instruction Following Tasks. IEEE Transactions on Cognitive and Developmental Systems
Evan King, Haoxiang Yu, Sangsu Lee, C. Julien (2023). "Get ready for a party": Exploring smarter smart spaces with help from large language models. arXiv.org
Courtney Tse Improving Human-Robot Communication of Hierarchical Task Planning through LLMs
Junwei Yu, Yepeng Ding, Hiroyuki Sato (2025). DynTaskMAS: A Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems. Proceedings of the ... International Conference on Automated Planning and Scheduling
Q. Luu, Xiyu Deng, Anh Van Ho, Yorie Nakahira (2024). Context-aware LLM-based Safe Control Against Latent Risks. arXiv.org
Avihai Giuili, Rotem Atari, A. Sintov (2025). ORACLE-Grasp: Zero-Shot Task-Oriented Robotic Grasping using Large Multimodal Models. arXiv.org
Azizjon Kobilov, Jianglin Lan (2025). Automatic Robot Task Planning by Integrating Large Language Model with Genetic Programming. arXiv.org
Shadi Abpeikar, Matt Garratt, Kathryn E. Kasmarik, S. Anavatti, Rafiqul Islam (2024). Integrating Large Language Models for Task Planning in Robots ‐ A case Study with NAO. International Conference Control and Robots
Matthew Muhoberac, Atharva Parikh, Nirvi Vakharia, S. Virani, Aco Radujevic, and 10 more (2025). State and Memory is All You Need for Robust and Reliable AI Agents. arXiv.org
Shuhao Liao, Xuxin Lv, Yuhong Cao, Jeric Lew, Wenjun Wu, and 1 more (2025). HELM: Human-Preferred Exploration with Language Models. arXiv.org
Jianfeng Liao, Haoyang Zhang, Haofu Qian, Qiwei Meng, Yinan Sun, and 4 more (2023). Decision-Making in Robotic Grasping with Large Language Models. International Conference on Intelligent Robotics and Applications
Nikhil Behari, Edwin Zhang, Yunfan Zhao, A. Taneja, Dheeraj M. Nagaraj, and 1 more (2024). A Decision-Language Model (DLM) for Dynamic Restless Multi-Armed Bandit Tasks in Public Health. Neural Information Processing Systems
Weizheng Wang, Ike Obi, Byung-Cheol Min (2025). Multi-Agent LLM Actor-Critic Framework for Social Robot Navigation. arXiv.org
Lorenzo Giusti, Ole Anton Werner, Riccardo Taiello, Matilde Carvalho Costa, Emre Tosun, and 6 more (2025). Federation of Agents: A Semantics-Aware Communication Fabric for Large-Scale Agentic AI. arXiv.org
Maximilian Holland, Kunal Chaudhari (2024). Large language model based agent for process planning of fiber composite structures. Manufacturing Letters
Wenjie Lin, Jin Wei-Kocsis (2025). Think, Reflect, Create: Metacognitive Learning for Zero-Shot Robotic Planning with LLMs. arXiv.org
Boye Niu, Yiliao Song, Kai Lian, Yifan Shen, Yu Yao, and 2 more (2025). Flow: Modularized Agentic Workflow Automation. International Conference on Learning Representations
Annabella Macaluso, Nicholas Cote, Sachin Chitta (2024). Toward Automated Programming for Robotic Assembly Using ChatGPT. IEEE International Conference on Robotics and Automation
Rodrigo P'erez-Dattari, Zhaoting Li, Robert Babuvska, Jens Kober, C. D. Santina (2024). Scalable Task Planning via Large Language Models and Structured World Representations
Armin Sadeghi, Stephen L. Smith (2017). Heterogeneous Task Allocation and Sequencing via Decentralized Large Neighborhood Search. Unmanned Systems
Antonin Sulc, Thorsten Hellert, Raimund Kammering, Hayden Houscher, Jason St. John (2024). Towards Agentic AI on Particle Accelerators. arXiv.org
Zeyu Wang, Frank P.-W. Lo, Qian Chen, Yongqi Zhang, Chen Lin, and 5 more (2025). An LLM-Enabled Multi-Agent Autonomous Mechatronics Design Framework. 2025 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)
Zhongyang Li, Fei Lu, Tengfan Fu, Guohui Tian (2025). From Demand to Grounded Plan: Task Customization and Planning for Service Robots With Deep Learning and LLMs. IEEE Robotics and Automation Letters
Víctor Rodríguez-Fernández, Alejandro Carrasco, Jason Cheng, Eli Scharf, P. M. Siew, and 1 more (2024). Language Models are Spacecraft Operators. arXiv.org
Junzhou Chen, Sidi Lu (2024). An Advanced Driving Agent with the Multimodal Large Language Model for Autonomous Vehicles. Most
Bharat Prakash, Tim Oates, T. Mohsenin (2024). Using LLMs for Augmenting Hierarchical Agents with Common Sense Priors. The Florida AI Research Society
Shiyi Liu, Haiying Shen, Shuai Che, Mahdi Ghandi, Mingqin Li (2025). HERA: Hybrid Edge-cloud Resource Allocation for Cost-Efficient AI Agents. arXiv.org
Alireza Kheirandish, Duo Xu, F. Fekri (2024). LLM-Augmented Symbolic Reinforcement Learning with Landmark-Based Task Decomposition. arXiv.org
Jiahong Xu, Zhiwei Zheng, Zaijun Wang (2024). LAC: Using LLM-based Agents as the Controller to Realize Embodied Robot. IEEE International Conference on Robotics and Biomimetics
Rohan Kadekodi, Zhan Jin, Keisuke Kamahori, Yile Gu, Sean Khatiri, and 3 more (2025). DualTune: Decoupled Fine-Tuning for On-Device Agentic Systems
Oleg Sautenkov, Yasheerah Yaqoot, Artem Lykov, Muhammad Ahsan Mustafa, Grik Tadevosyan, and 5 more (2025). UAV-VLA: Vision-Language-Action System for Large Scale Aerial Mission Generation. IEEE/ACM International Conference on Human-Robot Interaction
Jizhou Chen, Samuel Lee Cong (2025). AgentGuard: Repurposing Agentic Orchestrator for Safety Evaluation of Tool Orchestration. arXiv.org
Huao Li, Hossein Nourkhiz Mahjoub, Behdad Chalaki, Vaishnav Tadiparthi, Kwonjoon Lee, and 3 more (2024). Language Grounded Multi-agent Reinforcement Learning with Human-interpretable Communication. Neural Information Processing Systems
Michele Grimaldi, Carlo Cernicchiaro, Sebastian Realpe Rua, Alaaeddine El-Masri-El-Chaarani, Markus Buchholz, and 4 more (2025). Advancing Shared and Multi-Agent Autonomy in Underwater Missions: Integrating Knowledge Graphs and Retrieval-Augmented Generation. arXiv.org
OpenMind, Shaohong Zhong, Adam Zhou, Boyuan Chen, Homin Luo, and 1 more (2024). A Paragraph is All It Takes: Rich Robot Behaviors from Interacting, Trusted LLMs. arXiv.org
Hongqian Chen, Yun Tang, Antonios Tsourdos, Weisi Guo (2025). Contextualized Autonomous Drone Navigation Using LLMs Deployed in Edge-Cloud Computing. 2025 International Conference on Machine Learning and Autonomous Systems (ICMLAS)
Kun Chu, Xufeng Zhao, C. Weber, Stefan Wermter (2025). LLM+MAP: Bimanual Robot Task Planning using Large Language Models and Planning Domain Definition Language. arXiv.org
Chang Liu, Jun Zhao (2024). Resource Allocation in Large Language Model Integrated 6G Vehicular Networks. IEEE Vehicular Technology Conference
Xing-ming Guo, Darioush Keivan, U. Syed, Lianhui Qin, Huan Zhang, and 3 more (2024). ControlAgent: Automating Control System Design via Novel Integration of LLM Agents and Domain Expertise. arXiv.org
Prabha Sundaravadivel, Preetha Roselyn, Vedachalam Narayanaswamy, Vincent I. Jeyaraj, Aishree Ramesh, and 1 more (2024). Integrating image-based LLMs on edge-devices for underwater robotics. Defense + Commercial Sensing
Alessio Capitanelli, F. Mastrogiovanni (2023). A framework for neurosymbolic robot action planning using large language models. Frontiers Neurorobotics
Hongrui Chen, Yuanjiang Hu, Yun Gan, Shuang Wei, Muhua Zhang, and 1 more (2024). InspectionGPT: A Large Language Model-Based System for Inspection Task Planning. 2024 IEEE 13th Data Driven Control and Learning Systems Conference (DDCLS)
Rahel Rickenbach, Bruce Lee, René Zurbrügg, Carmen Amo Alonso, M. Zeilinger (2025). DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning. arXiv.org
Dimitris Panagopoulos, Adolfo Perrusquía, Weisi Guo (2025). LUCIFER: Language Understanding and Context-Infused Framework for Exploration and Behavior Refinement. arXiv.org
Ceng Zhang, Zhanhong Sun, G. Chirikjian (2025). Goal-Guided Reinforcement Learning: Leveraging Large Language Models for Long-Horizon Task Decomposition. IEEE International Conference on Robotics and Automation
Tianle Zhou, Jiakai Xu, Guanhong Liu, Jiaxiang Liu, Haonan Wang, and 1 more (2025). An approach for systematic decomposition of complex llm tasks
Jie Liu, Pan Zhou, Yingjun Du, Ah-Hwee Tan, Cees G. M. Snoek, and 2 more (2024). CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation. International Conference on Learning Representations
Seoyeon Choi, Kanghyun Ryu, Jonghoon Ock, Negar Mehr (2025). CRAFT: Coaching Reinforcement Learning Autonomously using Foundation Models for Multi-Robot Coordination Tasks. arXiv.org
Anubhav Shrimal, Stanley Kanagaraj, Kriti Biswas, Swarnalatha Raghuraman, Anish Nediyanchath, and 2 more (2024). MARCO: Multi-Agent Real-time Chat Orchestration. Conference on Empirical Methods in Natural Language Processing
Pengfei Du (2025). OmniNova:A General Multimodal Agent Framework. arXiv.org
Peteris Racinskis, Oskars Vismanis, Toms Eduards Zinars, Jānis Ārents, M. Greitans (2024). Towards Open-Set NLP-Based Multi-Level Planning for Robotic Tasks. Applied Sciences
Alejandro Carrasco, Victor Rodríguez-Fernández, Richard Linares (2024). Fine-tuning LLMs for Autonomous Spacecraft Control: A Case Study Using Kerbal Space Program. arXiv.org
Zhen Yue, Bi Sheng, Xing-tong Lu, Wei-qin Pan, Hai-peng Shi, and 2 more (2023). Robot Task Planning Based on Large Language Model Representing Knowledge with Directed Graph Structures. arXiv.org
Pranav Doma, Aliasghar Arab, Xuesu Xiao (2024). LLM-Enhanced Path Planning: Safe and Efficient Autonomous Navigation with Instructional Inputs. arXiv.org
Licong Xu, Milind Sarkar, A. Lonappan, Í. Zubeldia, Pablo Villanueva-Domingo, and 21 more (2025). Open Source Planning & Control System with Language Agents for Autonomous Scientific Discovery. arXiv.org
Xiangyan Liu, Rongxue Li, Wei Ji, Tao Lin (2023). Towards Robust Multi-Modal Reasoning via Model Selection. International Conference on Learning Representations
Anuj Sharma, William Grissom, Mark Griswold Designing MR Exams Using an Autonomous Multi-Agent Large Language Model System. ISMRM Annual Meeting
Huaiyuan Yao, Longchao Da, Vishnu Nandam, J. Turnau, Zhiwei Liu, and 2 more (2024). CoMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic. SDM
Wenkang Ji, Huaben Chen, Mingyang Chen, Guobin Zhu, Lufeng Xu, and 4 more (2025). GenSwarm: Scalable Multi-Robot Code-Policy Generation and Deployment via Language Models. arXiv.org
T. Gurunathan, Muhammad Shehrose Raza, Aswin Kumar Janakiraman, Md. Azim Khan, Biplab Pal, and 1 more (2025). Edge LLMs for Real-Time Contextual Understanding with Ground Robots. AAAI Spring Symposia
Carlos Jose Xavier Cruz (2024). Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations. arXiv.org
Connie Jiang, Yiqing Xu, David Hsu (2024). LLMs for Robotic Object Disambiguation. arXiv.org
Dimitrios Brodimas, Alexios N. Birbas, Dimitrios Kapolos, S. Denazis (2025). Intent-Based Infrastructure and Service Orchestration Using Agentic-AI. IEEE Open Journal of the Communications Society
Cathy Mengying Fang, Krzysztof Zielinski, Pattie Maes, Joe A. Paradiso, Bruce Blumberg, and 1 more (2024). Enabling Waypoint Generation for Collaborative Robots using LLMs and Mixed Reality. arXiv.org
Jielin Qiu, Mengdi Xu, William Jongwon Han, Seungwhan Moon, Ding Zhao (2023). Embodied Executable Policy Learning with Language-based Scene Summarization. North American Chapter of the Association for Computational Linguistics
Xinrui Lin, Yang-Chang Wu, Huanyu Yang, Yu Zhang, Yanyong Zhang, and 1 more (2024). CLMASP: Coupling Large Language Models with Answer Set Programming for Robotic Task Planning. arXiv.org
Bingzheng Gan, Yufan Zhao, Tianyi Zhang, Jing Huang, Yusu Li, and 3 more (2025). MASTER: A Multi-Agent System with LLM Specialized MCTS. North American Chapter of the Association for Computational Linguistics
Ruohao Li, Hongjun Liu, Leyi Zhao, Zisu Li, Jiawei Li, and 5 more (2025). SwarmSys: Decentralized Swarm-Inspired Agents for Scalable and Adaptive Reasoning
Sebastián R. Castro, Roberto Campbell, Nancy Lau, Octavio Villalobos, Jiaqi Duan, and 1 more (2025). Large Language Models are Autonomous Cyber Defenders. Conference on Algebraic Informatics
S. ArjunP, Andrew Melnik, G. C. Nandi (2024). Cognitive Planning for Object Goal Navigation using Generative AI Models
Lillian Wassim, Kamal Mohamed, Ali Hamdi (2024). LLM-DaaS: LLM-driven Drone-as-a-Service Operations from Text User Requests. arXiv.org
A. Masumori, Norihiro Maruyama, Itsuki Doi, Johnsmith, Hiroki Sato, and 1 more (2025). Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks
J. Tan, M. Motani (2023). Large Language Model (LLM) as a System of Multiple Expert Agents: An Approach to solve the Abstraction and Reasoning Corpus (ARC) Challenge. arXiv.org
Quanfeng Liang, Linchang Xiao, Miao Hu (2025). Automated Resource Orchestration for Large-Scale Heterogeneous Applications. International Conference on High Performance Scientific Computing
Arjun Vaithilingam Sudhakar (2025). Multi-Agent Language Models: Advancing Cooperation, Coordination, and Adaptation. arXiv.org
Alireza Salemi, Mihir Parmar, Palash Goyal, Yiwen Song, Jinsung Yoon, and 3 more (2025). LLM-based Multi-Agent Blackboard System for Information Discovery in Data Science
Jusheng Zhang, Yijia Fan, Kaitong Cai, Xiaofei Sun, Keze Wang (2025). OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration. arXiv.org
Xiaoxia Liu, Peng Di, Cong Li, Jun Sun, Jingyi Wang (2025). Efficient Function Orchestration for Large Language Models. arXiv.org
Yosuke Tsushima, Shu Yamamoto, A. A. Ravankar, J. V. S. Luces, Yasuhisa Hirata (2025). Task Planning for a Factory Robot Using Large Language Model. IEEE Robotics and Automation Letters
Alex Zhang, Khanh Nguyen, Jens Tuyls, Albert Lin, Karthik Narasimhan (2024). Language-guided World Models: A Model-based Approach to AI Control. SPLUROBONLP
Anjali R. Menon, Rohit K. Sharma, Priya Singh, Chengyu Wang, Aurora M. Ferreira, and 1 more (2025). Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models. arXiv.org
Yan Ding, Xiaohan Zhang (2023). Leveraging Commonsense Knowledge from Large Language Models for Task and Motion Planning
Miguel Ángel González Santamarta, Francisco J. Rodr'iguez-Lera, David Sobr'in-Hidalgo, Á. Guerrero-Higueras, Vicente Matellán Olivera (2025). Integrating Quantized LLMs into Robotics Systems as Edge AI to Leverage their Natural Language Processing Capabilities. arXiv.org
Zachary Ravichandran, Fernando Cladera, Jason Hughes, Varun Murali, M. A. Hsieh, and 3 more (2025). Deploying Foundation Model-Enabled Air and Ground Robots in the Field: Challenges and Opportunities. arXiv.org
Jiabao Ji, Yongchao Chen, Yang Zhang, R. Kompella, Chuchu Fan, and 2 more (2025). Collision- and Reachability-Aware Multi-Robot Control with Grounded LLM Planners. arXiv.org
Mengjun Wang, Yan Li, Shuai Li (2024). Robotic Assembly of Interlocking Blocks for Construction Based on Large Language Models. Construction Research Congress 2024
Daniel Buffum, Jack Akers, J. Kerley, Derek T. Anderson, Andrew R. Buck, and 1 more (2025). Explainable LLM-based drone autonomy derived from partially observable geospatial data. Defense + Security
Mohsen Seyedkazemi Ardebili, Andrea Bartolini (2025). KubeIntellect: A Modular LLM-Orchestrated Agent Framework for End-to-End Kubernetes Management
Zidan Wang, Rui Shen, Bradly C. Stadie (2024). Wonderful Team: Zero-Shot Physical Task Planning with Visual LLMs
Gurusha Juneja, Subhabrata Dutta, Tanmoy Chakraborty (2024). LM2: A Simple Society of Language Models Solves Complex Reasoning. Conference on Empirical Methods in Natural Language Processing
Shivam Singh, Karthik Swaminathan, Nabanita Dash, Ramandeep Singh, Snehasis Banerjee, and 2 more (2025). AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement. IEEE International Conference on Robotics and Automation
Jared Strader, Aaron Ray, Jacob Arkin, Mason B. Peterson, Yun Chang, and 9 more (2025). Language-Grounded Hierarchical Planning and Execution with Multi-Robot 3D Scene Graphs. arXiv.org
Ike Obi, Vishnunandan L. N. Venkatesh, Weizheng Wang, Ruiqi Wang, Dayoon Suh, and 3 more (2025). SafePlan: Leveraging Formal Logic and Chain-of-Thought Reasoning for Enhanced Safety in LLM-based Robotic Task Planning. arXiv.org
Zhen Zhao, Dunbing Tang, Haihua Zhu, Zequn Zhang, Kai Chen, and 2 more (2024). A Large Language Model-based multi-agent manufacturing system for intelligent shopfloor. Advanced Engineering Informatics
Xufeng Zhao, C. Weber, Stefan Wermter (2024). Agentic Skill Discovery. arXiv.org
Fangyuan Wang, Shipeng Lyu, Peng Zhou, Anqing Duan, Guodong Guo, and 1 more (2025). Instruction-Augmented Long-Horizon Planning: Embedding Grounding Mechanisms in Embodied Mobile Manipulation. AAAI Conference on Artificial Intelligence
Robert E. Wray, James R. Kirk, John E. Laird (2024). Eliciting Problem Specifications via Large Language Models. arXiv.org
Marco Becattini, R. Verdecchia, Enrico Vicario (2025). SALLMA: A Software Architecture for LLM-Based Multi-Agent Systems. 2025 IEEE/ACM International Workshop New Trends in Software Architecture (SATrends)
Ettilla Mohiuddin Eumi, Hussein Abbass, Nadine Marcus (2025). SwarmChat: An LLM-Based, Context-Aware Multimodal Interaction System for Robotic Swarms. International Conference on Swarm Intelligence
Mingfeng Yuan, Letian Wang, Steven L. Waslander (2025). OpenNav: Open-World Navigation with Multimodal Large Language Models. arXiv.org
Jin Aoyama, Sudesna Chakraborty, Takeshi Morita, S. Egami, Takanori Ugai, and 1 more (2025). Household Task Planning with Multi-Objects State and Relationship Using Large Language Models Based Preconditions Verification. International Conference on Agents and Artificial Intelligence
Tianxing Zhou, Zhirui Wang, Haojia Ao, Guangyan Chen, Boyang Xing, and 3 more (2025). STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner. arXiv.org
Yisheng Zhang, Zhigang Wang, Shengmin Zhang, Yanlong Peng, Ming Chen (2023). Boosting Robot Intelligence in Practice: Enhancing Robot Task Planning with Large Language Models. International Conference Robotics and Automation Engineering
Wenyi Jiang, Baowei Xv, Zhihao Cui (2024). Behavior-Actor: Behavioral Decomposition and Efficient-Training for Robotic Manipulation. IEEE/RJS International Conference on Intelligent RObots and Systems
Biddut Sarker Bijoy, Mohammad Saqib Hasan, Pegah Alipoormolabashi, Avirup Sil, Aruna Balasubramanian, and 1 more (2025). ProST: Progressive Sub-task Training for Pareto-Optimal Multi-agent Systems Using Small Language Models
Soheyl Massoudi, Mark Fuge (2025). Agentic Large Language Models for Conceptual Systems Engineering and Design. arXiv.org
Qinghua Lu, Liming Zhu, Xiwei Xu, Zhenchang Xing, Stefan Harrer, and 3 more B UILDING THE F UTURE OF R ESPONSIBLE AI: A P ATTERN -O RIENTED R EFERENCE A RCHITECTURE FOR D ESIGNING L ARGE L ANGUAGE M ODEL BASED A GENTS
Mingcong Chen, Siqi Fan, Guanglin Cao, Yun-hui Liu, Hongbin Liu (2025). USPilot: An Embodied Robotic Assistant Ultrasound System With a Large Language Model Enhanced Graph Planner. IEEE Robotics and Automation Letters
D. Paulius, Alejandro Agostini, Benedict Quartey, G. Konidaris (2024). Bootstrapping Object-Level Planning with Large Language Models. IEEE International Conference on Robotics and Automation
Niccolo' Turcato, Matteo Iovino, Aris Synodinos, Alberto Dalla Libera, Ruggero Carli, and 1 more (2025). Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation With Large Language Models. IEEE Robotics and Automation Letters
Mehreen Naeem, Andrew Melnik, Michael Beetz (2025). Grounding Language Models with Semantic Digital Twins for Robotic Planning. arXiv.org
Hyungjoo Kim, Sungjae Min, Gyuree Kang, Jihyeok Kim, David Hyunchul Shim (2024). Fly by Book: How to Train a Humanoid Robot to Fly an Airplane using Large Language Models. IEEE/RJS International Conference on Intelligent RObots and Systems
Timothée Anne, Noah Syrkis, Meriem Elhosni, Florian Turati, Franck Legendre, and 2 more (2024). Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control. IEEE Transactions on Games
Site Hu, Takato Horii, Takayuki Nagai (2024). Adaptive and transparent decision-making in autonomous robots through graph-structured world models. Adv. Robotics
Lina Zhao, Jiaxing Bai, Zihao Bian, Qingyue Chen, Yafang Li, and 4 more (2025). Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery. arXiv.org
Shalini Katyayani Koney (2025). LLM-Trust: Verifiable Intelligence for Distributed Systems Control. European Modern Studies Journal
Cristiano Caissutti, Estelle Gerbier, Ehsan Khorrambakht, Paolo Marinelli, Andrea Munafo, and 1 more (2025). Shared Autonomy through LLMs and Reinforcement Learning for Applications to Ship Hull Inspections
Huihui Guo, Huilong Pi, Yunchuan Qin, Z. Tang, Kenli Li (2025). Leveraging Pre-trained Large Language Models with Refined Prompting for Online Task and Motion Planning
Rohan Gupta, Trevor Asbery, Zain Merchant, Abrar Anwar, Jesse Thomason (2025). RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning
Weijie Zhou, Yi Peng, Manli Tao, Chaoyang Zhao, Honghui Dong, and 2 more (2025). LightPlanner: Unleashing the Reasoning Capabilities of Lightweight Large Language Models in Task Planning. arXiv.org
Miquel Sirera Perelló, Joshua Groen, Wan Liu, Stratis Ioannidis, Kaushik R. Chowdhury (2024). JARVIS: Disjoint Large Language Models on Radio VLANs for Intelligent Services. IEEE Military Communications Conference
Peijie Yu, Yifan Yang, Jinjian Li, Zelong Zhang, Haorui Wang, and 2 more (2025). Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents through Related and Dynamic Missions. arXiv.org
Seokjoon Kwon, Jae-Hyeon Park, Hee-Deok Jang, CheolLae Roh, D. Chang (2025). Large Language Model Based Autonomous Task Planning for Abstract Commands. IEEE International Conference on Robotics and Automation
Unai Ruiz-Gonzalez, Alain Andres, Pedro G. Bascoy, J. Ser (2024). Words as Beacons: Guiding RL Agents with High-Level Language Prompts. arXiv.org
Taylor Webb, S. S. Mondal, Ida Momennejad (2025). A brain-inspired agentic architecture to improve planning with LLMs. Nature Communications
O. Joglekar, Tal Lancewicki, Shir Kozlovsky, Vladimir Tchuiev, Zohar Feldman, and 1 more (2024). Towards Natural Language-Driven Assembly Using Foundation Models. arXiv.org
Paul Mingzheng Tang, Kenji Kah Hoe Leong, Nowshad Shaik, H. Lau (2024). Automated Conversion of Static to Dynamic Scheduler via Natural Language. arXiv.org
Yanggang Xu, Weijie Hong, Jirong Zha, Geng Chen, Jianfeng Zheng, and 2 more (2025). Scalable UAV Multi-Hop Networking via Multi-Agent Reinforcement Learning with Large Language Models. arXiv.org
Zheyuan Zhang, Lin Ge, Hongjiang Li, Weicheng Zhu, Chuxu Zhang, and 1 more (2025). MAPRO: Recasting Multi-Agent Prompt Optimization as Maximum a Posteriori Inference
Amin Tabrizian, Pranav Gupta, Abenezer Taye, James Jones, E. Thompson, and 4 more (2024). Using Large Language Models to Automate Flight Planning Under Wind Hazards. Symposium on Dependable Autonomic and Secure Computing
Ruiyang Wang, Hao-Lun Hsu, David Hunt, Shaocheng Luo, Jiwoo Kim, and 1 more (2025). LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search
Runqin Gao, Jiamin Shi, Shu Tian, Shitao Chen (2024). General Planning Method for Humanoid Collaborative Robots Using Large Language Models. ACM Cloud and Autonomic Computing Conference
Zachary Ravichandran, Ignacio Hounie, Fernando Cladera, Alejandro Ribeiro, George J. Pappas, and 1 more (2025). Distilling On-device Language Models for Robot Planning with Minimal Human Intervention. arXiv.org
Qiong Wu, Yu Xie, Pingyi Fan, Dong Qin, Kezhi Wang, and 2 more (2025). Large Language Model-Based Task Offloading and Resource Allocation for Digital Twin Edge Computing Networks. arXiv.org
Émiland Garrabé, Pierre Teixeira, Mahdi Khoramshahi, Stéphane Doncieux (2024). Enhancing Robustness in Language-Driven Robotics: A Modular Approach to Failure Reduction. arXiv.org
Charles Fleming, Ashish Kundu, R. Kompella (2025). Uncertainty-Aware, Risk-Adaptive Access Control for Agentic Systems using an LLM-Judged TBAC Model
Pengcheng Zhou, Yinglun Feng, Halimulati Julaiti, Zhongliang Yang (2025). Why do AI agents communicate in human language?. arXiv.org
Chao Wang, Stephan Hasler, Daniel Tanneberg, Felix Ocker, F. Joublin LaMI: Large Language Models Driven Multi-Modal Interface for Human-Robot Communication
Aline Dobrovsky, Konstantin Schekotihin, C. Burmer (2025). Intelligent Assistants for the Semiconductor Failure Analysis with LLM-Based Planning Agents
Thomas Carta, Clément Romac, Loris Gaven, Pierre-Yves Oudeyer, Olivier Sigaud, and 1 more (2025). HERAKLES: Hierarchical Skill Compilation for Open-ended LLM Agents. arXiv.org
Daniel Weiner, Raj Korpan (2025). Hybrid Voting-Based Task Assignment in Modular Construction Scenarios. arXiv.org
Yaran Chen, Wenbo Cui, Yuanwen Chen, Mining Tan, Xinyao Zhang, and 2 more (2023). RoboGPT: an intelligent agent of making embodied long-term decisions for daily instruction tasks
Hu Yifan, Bin-Bin Hu, Yuan Bowen, Hai-Tao Zhang (2025). LLM Coach: Reward Shaping for Reinforcement Learning-Based Navigation Agent. 2025 Joint International Conference on Automation-Intelligence-Safety (ICAIS) & International Symposium on Autonomous Systems (ISAS)
Tomoya Kawabe, T. Nishi, Ziang Liu 004, Tomofumi Fujiwara (2024). Task Planning for Robot Manipulator Using Natural Language Task Input with Large Language Models. 2024 IEEE 20th International Conference on Automation Science and Engineering (CASE)
Qimeng Li, Raffaele Gravina, Giancarlo Fortino Multi-Agent Systems Meet Large Language Models: Architectures, Synergies, and Future Directions
Chandan Kumar Singh, Devesh Kumar, Vipul Sanap, Rajesh Sinha (2025). LLM-RSPF: Large Language Model-Based Robotic System Planning Framework for Domain Specific Use-cases. IEEE Workshop/Winter Conference on Applications of Computer Vision
Siddeshwar Raghavan, Tanwi Mallick (2025). MOSAIC: Multi-agent Orchestration for Task-Intelligent Scientific Coding
Derik Chan, YiBo Wu, DaChuan Bai, Tom Mak, Tony Chan, and 2 more (2024). The Survey for a Hierarchical Resource Management Framework Enabled with LLM-based Agents. 2024 IEEE Future Networks World Forum (FNWF)
MengGuo Fu, J. Gou (2025). Design of Task Allocation and Decision-Making Styles for AI Agents Based on LLM. 2025 10th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)
Yoshiki Yano, Kazuki Shibata, Maarten Kokshoorn, Takamitsu Matsubara (2025). ICCO: Learning an Instruction-conditioned Coordinator for Language-guided Task-aligned Multi-robot Control. arXiv.org
David J. Porfirio, Vincent Hsiao, Morgan Fine-Morris, Leslie Smith, Laura M. Hiatt (2025). Bootstrapping Human-Like Planning via LLMs. arXiv.org
P. B. D. Costa, P. C. D. Santos, J. Boaro, D. D. S. Moraes, J. C. Duarte, and 1 more (2024). Experimenting with Planning and Reasoning in Ad Hoc Teamwork Environments with Large Language Models. International Conference on Agents and Artificial Intelligence
Joao Vitor de Carvalho Silva, D. Macharet (2025). Can LLM Agents Solve Collaborative Tasks? A Study on Urgency-Aware Planning and Coordination. arXiv.org
Fei Lin, Tengchao Zhang, Qinghua Ni, Jun Huang, Siji Ma, and 3 more (2025). Talk Less, Fly Lighter: Autonomous Semantic Compression for UAV Swarm Communication via LLMs. arXiv.org
Rasoul Zahedifar, Sayyed Ali Mirghasemi, M. Baghshah, Alireza Taheri (2025). LLM-Agent-Controller: A Universal Multi-Agent Large Language Model System as a Control Engineer. arXiv.org
Mohammad Narimani, S.A. Emami (2025). AgenticControl: An Automated Control Design Framework Using Large Language Models. arXiv.org
Haolin Wu, Yuecheng Liu, Junyi Dong, Heng Zhang, Sitong Mao, and 3 more (2025). ASCENT: Autonomous Skill Learning Toward Complex Embodied Tasks With Foundation Models. IEEE International Conference on Robotics and Automation
Tzoulio Chamiti, Nikolaos Passalis, A. Tefas (2025). Large Models in Dialogue for Active Perception and Anomaly Detection. arXiv.org
Francesco Argenziano, Elena Umili, Francesco Leotta, Daniele Nardi (2025). Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning
No authors found Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device LLM Agents
No authors found LUCI: Multi-Application Orchestration Agent
No authors found OKR-A GENT : A N O BJECT AND K EY R ESULTS D RIVEN A GENT S YSTEM WITH H IERARCHICAL S ELF - C OLLABORATION AND S ELF -E VALUATION
Benjamin Cooper, John Grimes, M. Planer, Letitia Li, Daniel Wallach, and 7 more A Data-Efficient Model-based Task Decomposition Approach for Massive Satellite Constellations
Karan Baijal, Calvin Qiu, Jennifer Sun AdaTAMP: Adaptive Task and Motion Planning with LLM-based Embodied Agents
Min-Suck Kwon, †. YoungJ.Kim 거대 언어 모델을 이용한 뉴로-심볼릭 작업 재계획법 Neuro-Symbolic Task Replanning using Large Language Models
Yaran Chen, Wenbo Cui, Yuanwen Chen, Mining Tan, Xinyao Zhang, and 5 more RoboGPT: an LLM-based Embodied Long-term Decision Making agent for Instruction Following Tasks
Krishan Rana, †. SouravGarg, Jesse Haviland, Jad Abou-Chakra, Ian Reid, and 3 more Leveraging 3D Scene Graphs in Large Language Models for Task Planning
No authors found RAG-Inspired Robotic Task Planning Using Large Language Models
Enrico Saccon, Edoardo Lamon, Luigi Palopoli, M. Roveri PLANTOR: LLM-Aided Knowledge Base Generation for Temporal Planning of Robotic Tasks
Zihe Ji, Mehdi Zadem, Sao Mai Nguyen Dynamic Symbolic Representation and LLM to Enhance Task Abstraction in Hierarchical Reinforcement Learning
No authors found L ARGE L ANGUAGE M ODELS AS D ECISION M AKERS FOR A UTONOMOUS D RIVING
Report
Status
 
Gather sources
500 sources found
 
Screen sources
444 sources included
(report limited to 200)
 
Extract data
3552 data points extracted
 
Generate report
Chat
Got some follow-up questions?
Sign up or sign in to chat with this report.
/review/2e548b0c-47b1-468f-afda-5fefbc9a9080