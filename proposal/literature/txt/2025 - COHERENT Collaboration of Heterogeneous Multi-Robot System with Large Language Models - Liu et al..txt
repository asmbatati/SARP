--- Page 1 ---
COHERENT: Collaboration of Heterogeneous Multi-Robot System with
Large Language Models
Kehui Liu1,2,∗,†, Zixin Tang2,3,∗,†, Dong Wang2,B, Zhigang Wang2, Xuelong Li2,4, Bin Zhao1,2,B
Abstract— Leveraging the powerful reasoning capabilities
of large language models (LLMs), recent LLM-based robot
task planning methods yield promising results. However, they
mainly focus on single or multiple homogeneous robots on
simple tasks. Practically, complex long-horizon tasks always
require collaboration among multiple heterogeneous robots
especially with more complex action spaces, which makes
these tasks more challenging. To this end, we propose CO-
HERENT, a novel LLM-based task planning framework for
collaboration of heterogeneous multi-robot systems including
quadrotors, robotic dogs, and robotic arms. Specifically, a
Proposal-Execution-Feedback-Adjustment (PEFA) mechanism
is designed to decompose and assign actions for individual
robots, where a centralized task assigner makes a task planning
proposal to decompose the complex task into subtasks, and then
assigns subtasks to robot executors. Each robot executor selects
a feasible action to implement the assigned subtask and reports
self-reflection feedback to the task assigner for plan adjustment.
The PEFA loops until the task is completed. Moreover, we
create a challenging heterogeneous multi-robot task planning
benchmark encompassing 100 complex long-horizon tasks. The
experimental results show that our work surpasses the previous
methods by a large margin in terms of success rate and execu-
tion efficiency. The experimental videos, code, and benchmark
are released at https://github.com/MrKeee/COHERENT.
I. INTRODUCTION
With the rapid development of deep learning technolo-
gies in robotics, learning-based methods with extensive data
produce impressive results both in single-robot [1], [2] and
multi-robot systems [3]. However, even with the continuous
expansion of datasets [4], [5], the performances of these
methods still struggle with generalization. The reason is
that these methods lack comprehensive prior knowledge in
dealing with unseen tasks, scenes and new robot types.
Encouraged by the rich world knowledge of pre-trained
large language models (LLMs) and their excellent capability
in complex reasoning, many recent works [6], [7], [8] have
utilized LLMs to analyze and decompose complex task in-
structions, achieving promising results in robot task planning.
As shown in Figure 1(a), many single robot task planning
methods leverage few-shot prompting techniques to generate
multi-stage task and motion plans [9], and even robot control
code [10], [11]. Compared to single-robot systems, multi-
robot systems have attracted more attention since they are
able to handle more complex tasks [12], [13], [14] in recent
years. For homogeneous multi-robot systems, some works
1Northwestern Polytechnical University. 2Shanghai Artificial Intelligence
Laboratory. 3The Chinese University of Hong Kong. 4Institute of Artificial
Intelligence, China Telecom Corp Ltd.
∗Equal contribution. †Work is done during internship at Shanghai Arti-
ficial Intelligence Laboratory. BCorresponding author.
(a) Single robot planning
 Prompt Management
Robot Assistant LLM
Application Scenarios
(b) Homogeneous multiple robots planning
Dialogue
Robot
 Assistant
 LLMs
(c)  Our framework for heterogeneous multiple robots 
Input
Task 
Assigner
LLM
Robot Executor LLMs 
Application Scenarios
Application Scenarios
Fig. 1.
Comparisons of LLM-based planning among (a) single-robot, (b)
homogeneous multi-robot, and (c) heterogeneous multi-robot. In contrast to
previous methods, COHERENT focuses on task allocation and collabora-
tion among different types of robots, aiming to collaboratively accomplish
complex and long-horizon tasks.
[15], [16], [17], [18] have found that the adoption of dialogue
and discussion between multiple LLM-enabled robots can
release cognitive synergy ability, improve reasoning, and
reduce hallucinations in complex tasks, as depicted in Figure
1(b). In [19] and [20], they try to generate detailed task plan-
ning via multi-turn dialogue and discussion among individual
robots. However, there are many practical scenes that require
collaboration between multiple heterogeneous robots, where
each is characterized by different action skills. To generate
correct task planning for heterogeneous robot systems, the
challenge lies in accurately understanding each robot’s action
capabilities under changing environments, and conducting
accurate task decomposition, allocation, and collaboration
among different robots, which are not fully explored yet.
To this end, we present COHERENT, a novel LLM-based
centralized hierarchical framework for heterogeneous multi-
robot task planning as shown in Figure 1(c). Our framework
conducts multiple Proposal-Execution-Feedback-Adjustment
(PEFA) cycles between a centralized task assigner and indi-
vidual robot executors to finish a complex long-horizon task.
The centralized task assigner is instantiated by prompting an
LLM to decompose high-level task instructions into subtasks
and assign each subtask to different robots. Each robot
executor is equipped with an independent LLM and tries
to accomplish the assigned subtask. Specifically, given a
complex long-horizon task that requires heterogeneous robot
collaboration, the task assigner first gathers all the observa-
2025 IEEE International Conference on Robotics and Automation (ICRA)
May 19-23, 2025. Atlanta, USA
979-8-3315-4139-2/25/$31.00 ©2025 IEEE
10208
2025 IEEE International Conference on Robotics and Automation (ICRA) | 979-8-3315-4139-2/25/$31.00 ©2025 IEEE | DOI: 10.1109/ICRA55743.2025.11127808
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on January 26,2026 at 09:03:07 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 2 ---
tions and makes an initial task planning and decomposition
proposal. Then, each robot tries to complete the assigned
subtask by executing an action from the feasible action list
of the robot, and a summarized feedback is reported to the
centralized task assigner via conducting a self-reflection on
whether the subtask is completed. Finally, the centralized
task assigner makes an adjusted new task planning proposal
based on execution feedback and historical plans to com-
plete the overall task goal. This PEFA mechanism planning
process will run in a loop until the task goal is achieved.
To demonstrate the validity of our framework, we con-
struct a more challenging benchmark for evaluating task
planning of heterogeneous multi-robot systems than previous
state-of-the-art methods. This benchmark consists of five
different large-scale, realistic simulated scenes and 100 tasks
with varying levels of complexity. It comprises three kinds of
robots with different functions, i.e., quadrotors, robotic dogs,
and robotic arms. Experimental results on this benchmark
have confirmed the superiority of COHERENT that achieves
a higher task success rate and execution efficiency. We
summarize the contributions of this work as follows:
(1) We propose a centralized hierarchical framework
which is more beneficial for heterogeneous multi-robot sys-
tems and enables efficient and precise task collaboration by
fully leveraging robots with different action spaces.
(2)
We
present
an
LLM-based
proposal-execution-
feedback-adjustment cyclic mechanism that efficiently lever-
ages interactive feedback and adjustment to schedule dif-
ferent types of robots in heterogeneous multi-robot task
planning.
(3) We construct a more challenging heterogeneous multi-
robot benchmark containing 5 large scenes and 100 long-
horizon tasks. The experimental results demonstrate the
superiority of our work.
II. RELATED WORKS
A. Task Planning in Robotics
Prior works can be roughly classified into three categories:
classic logic-based, learning-based, and LLM-based. Classic
logic-based methods [21], [22], [23], [24], primarily utiliz-
ing Planning Domain Description Language (PDDL) [21],
leverage predicate logic solvers for task planning. However,
these methods are unsuitable for large-scale open world and
unknown environment exploration. Learning-based methods
[25], [26] are represented by hierarchical reinforcement
learning (HRL), which demonstrates more adaptability and
flexibility in handling dynamic environments. Despite the
progress made in HRL [27], these methods continue to
grapple with the well-recognized challenge of learning in-
efficiency, which poses substantial hurdles in their practi-
cal applicability within real-world environments. Recently,
LLMs with powerful commonsense knowledge and reason-
ing ability present a promising avenue for addressing these
limitations [28]. Several studies have been proposed to tackle
various complex scenarios, such as household manipulation
[29], [30], [31], [11] and navigation [17], [32]. These LLM-
based methods with zero-shot [6], [7] or few-shot [8] prompts
demonstrate robust generalization toward novel instructions
and unseen environments.
B. Multi-robot Planners based on LLMs
According to the decision-making scheme, multi-robot
planners based on LLMs can be categorized into two frame-
works: decentralized and centralized. In dialogue-style meth-
ods [19], [20], [33], each robot delegated to an LLM agent
exchanges its abilities and observations through communica-
tions to determine the next action. For example, RoCo [19]
proposes a multi-round dialogue framework with feedback to
solve table-top manipulation tasks. Zhang et al. [20] propose
a modular dialogue-style framework for embodied agents
to plan, communicate, and cooperate in VirtualHome-Social
[34], [35]. Liu et al. [33] utilizes the communication module
to make ad hoc agent join the original team. However, the
prompt length escalates considerably along with the number
of robots involved and the iteration of dialogue [36], [19],
resulting in unstable performance due to LLM’s inferiority
in long-context reasoning. Conversely, centralized methods
[37], [36] utilize only one central LLM to decompose and
allocate the work for all robots at each planning iteration.
Chen et al. [36] compare both dialogue-style and central-
ized paradigms on four multi-agent 2D task scenarios, and
demonstrate that centralized communication shows a better
task success rate and token efficiency than the other. Unlike
most studies merely involving homogeneous settings, in this
paper, we focus on designing a heterogeneous multi-robot
system in large-scale realistic environments.
III. METHOD
As shown in Figure 2, COHERENT conducts the task as-
signment and robot execution in multiple loops of Proposal-
Execution-Feedback-Adjustment (PEFA). We consider a liv-
ing room scenario with a low coffee table and a high
dining table. Three types of robots are tasked with the task
instruction I: Put the apple from the coffee table to the dining
table. This typical heterogeneous robot collaboration task
requires a quadrotor to serve as a transport bridge between
the robotic dog and the robotic arm. In this section, we detail
the key components of our PEFA mechanism through this
example.
A. Task Planning Proposal
As shown in Figure 2(a), a centralized Task Assigner LLM
takes the instruction I as input. Meanwhile, it considers the
task background, the capabilities and partial observations
of all robots, historical dialogue records, and important
notes within the prompt. Specifically, the task background
describes our heterogeneous multi-robot settings, and each
robot’s capabilities are represented to distinguish different
action spaces. The observations of each robot are converted
into text from a graph structure, which is expressed by the
relation(node1, node2) format, e.g., ON(apple, coffee
table), and just include visible objects in their respective
rooms. Note that each robot is unaware of environments in
other rooms and objects within closed containers. Dialogue
10209
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on January 26,2026 at 09:03:07 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 3 ---
···
···
 (a) Proposal
Input：Put the apple from the 
coffee table to the dining table.
 
  
Initial Proposal
• Robotic Dog:Take the apple 
to quadrotor’s basket.
• Quadrotor: ……
• Robotic Arm: ……
Controller
Robot Executor
 (b) Execution 
Assigned 
Robot 
Prompt 
Robot Executor LLM 
Action 
Validation
Success!
Fail？
OR
Failure Feedback
Success Feedback
•
 Fully satisfies the subtask’s plan.
•
Partially satisfies the subtask’s plan. 
Execution
Success
Robot Capabilities
Text
Quadrotor
Robotic Arm
Robotic Dog
Update Proposal
• Robotic Dog: ……
• Quadrotor: Land on table with 
the apple.
• Robotic Arm: ……
 (d) Adjustment
Task Assigner LLM 
···
Plan Adjustment
Initial Prompt
Dialogue History
•
Task Assigner：
I suggest the robotic dog ... 
Following your instructions, I have 
executed ... 
•
Task Assigner：
I suggest the quadrotor ... 
Following your instructions, I have 
executed ... 
···
Dialogue History
Updated Observations
Feedback
OR
· · ·
Plan
Action List
···
•
[movetowards] 
<basket> 
•
[movetowards] 
<bedroom>
•
[grab] <apple>  
Action List
Potential 
Reasons
•
 Need the help of other robots.
•
The generated action is not executable. 
Execution 
Results
···
Fail
Robot Observations
Graph 
Structure
[node] [edge]
Proposal Plan
 (c) Feedback
Task Assigner
Simulation
···
Fig. 2.
PEFA mechanism in COHERENT for heterogeneous multi-robot task planning. It consists of two stages, i.e., task assigner and robot executor.
The proposal module decomposes the human instruction into subgoals that can be assigned to a specific robot. The execution module further maps the
subgoal to an executable action. Additionally, the Feedback and Adjustment modules are designed for amendment or advancement of subtasks to complete
the instruction.
history stores memories of historical task planning propos-
als and execution feedback as shown in Figure 2(d), and
important notes are defined by some critical tips for special
situations, as the fixed prompts starting with keyword Note.
The information is fused to form a long text prompt for
Task Assigner LLM. The output is a task planning proposal,
composed of one assigned robot and one subtask to be
finished in the format <assigned robot>: subtask.
The complete and detailed input/output formats are shown
in the supplemental videos.
In the given example, using the prompts designed above
as input, Task Assigner LLM assigns specific subtasks to
different robots as the initial proposal in the format:
1) <robotic dog>: pick up the <apple>
and give it to <quadrotor>.
2) <quadrotor>: transport the <apple>
to the <dining table>.
3) <robotic arm>: put the <apple> on
the <dining table>.
Based on the sequential order, the Task Assigner LLM
outputs the first subtask to the Robot Executor LLM of
the robotic dog in the next module. Each reasoning process
and initial proposal will be stored in the dialogue history to
update the next proposal with a different robot or plan.
B. Assigned Subtasks Execution
As shown in Figure 2(b), the Execution Module takes the
proposal plan for the assigned robot as input and checks
if the assigned subtask is executable by the assigned robot.
Specifically, each assigned robot is equipped with one spe-
cific Robot Execution LLM, whose prompt is construed by
the proposal plan, capabilities, partial observations and an
executable action list of the assigned robot. The action list is
generated based on the current state and observations using
predefined rules as shown in Table I. Note that the prompts of
the different robots from the same robot type have the same
capabilities but different observations and action list at each
timestep. Considering the partial observation and limitations
TABLE I
THE ACTION LIST FOR DIFFERENT TYPES OF ROBOTS.
Robot
Action List
Quadrotor
[land on] <surface>
[movetowards] <surface>/<next room>
[takeoff from] <surface>
Robotic Dog
[open] <container>/<door>
[close] <container>/<door>
[grab] <object>
[putinto] <object> into <container>
[puton] <object> on <surface>
[movetowards] <object>
Robotic Arm
[open] <container>
[close] <container>
[grab] <object>
[putinto] <object> into <container>
[puton] <object> on <surface>
in the capability of the assigned robot, the action validation
process will further determine whether it is executable in the
physical world before outputting the action assigned to the
robot. We assume that there is a robotic dog. For example,
the action [puton] <apple> on <dining table>
is not executable due to the height limitation. In such cases,
the next Feedback Module analyzes the failure in detail and
sends the feedback to the Task Assigner. If the action is
executable, it returns the task’s progress to the Feedback
Module and then proceeds to the next subtask.
For the example considered, the Robot Executor LLM acts
as the action selection policy to select the most appropriate
action, e.g., [grab] <apple>. However, when hallucina-
tions occur, the proposal might instruct the robotic dog to
pick up the apple before it has approached it. This is an
incorrect action because the apple is not within the robotic
dog’s manipulation range. In such cases, the robotic dog will
remain still and wait for the correct instruction.
C. Robot Execution Feedback
Using the results of the action validation process as input,
the self-reflection provides low-level execution feedback
10210
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on January 26,2026 at 09:03:07 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 4 ---
S1: Merom_1_int
S2: Pomaria_1_int
S4: restaurant_brunch
S5: house_double_floor_lower
S3: grocery_store_cafe
Robotic Arm
Robotic Dog
Quadrotor
Each type task distribution and average step counts statistics
Mono-type task
Dual-type task
Trio-type task
30％
38％
32％
6.2
10.3
13.4
(a)
(b)
(c)
GT Step
Type
Fig. 3.
The illustration of five scenes and three heterogeneous robots in our benchmark. In subfigure (c), the distribution of various types of tasks within
the benchmark is displayed in the pie chart, along with the histogram showing the average ground truth (GT) steps for each type of task.
for high-level subtask decomposition in the next iteration,
enabling bottom-up task correction. As shown in Figure 2(c),
this feedback includes corrections after action failures and
progress updates after successful executions.
Specifically, failure feedback demonstrates the mistake in
the subtask proposal or action execution. For the failure
feedback, there are three typical situations. First, the proposal
contains a fully wrong step to complete I, often caused by
LLM hallucinations. Second, the subtask proposals are cor-
rectly generated but assigned to the wrong robot, leading to
execution issues. Third, even with the correct robot assigned,
the action cannot be performed due to execution limitations.
For the success feedback, the assigned robot will analyze
whether the executed action fully satisfies the subtask. If the
subtask requires multiple steps and the current action only
partially completes it, the task’s execution progress will be
updated and fed back to the Task Assigner, indicating that
the subtask is not fully completed and further actions are
required until the assigned robot finishes its subtask.
For example, if the robotic dog grabs the apple, it will
be instructed to move toward the quadrotor as the next step.
However, if the robotic dog is not near the coffee table yet,
the failure feedback will indicate that it is too far from the
apple to grab. In the case of an incorrect task assignment to
another robot, the feedback will clarify that the robot lacks
the capability to complete the task, requiring the assistance
of a different type of robot.
D. Subtask Proposal Adjustment
As shown in Figure 2(d), the Adjustment Module gath-
ers all task-level information and appends the execution
feedback to the dialogue history from the most recent five
iterations to improve token efficiency, which sets a solid
foundation for a new PEFA cycle. This module supports the
correction to the next subtask, establishing a dynamic and
adaptive assigning-execution loop for the long-horizon task
I.
IV. EXPERIMENTS
A. Benchmark
As shown in Figure 3, we create a large-scale realistic
embodied benchmark tailored for heterogeneous multi-robot
collaboration, including quadrotors, robotic dogs, and robotic
arms. Built upon the BEHAVIOR-1K platform [39], our
benchmark covers 5 typical real-world scenes: 2 apartment
scenes (S1, S2), 1 apartment with garden scene (S5), 1
grocery store (S3) and 1 restaurant (S4), with a wide range
of interactive objects (both rigid and articulated) and various
layouts (e.g., multi-room and multi-floor). The ground truth
(GT) of each task represents the optimal number of steps
for completion. Based on the minimum necessary number of
robot types to perform each task, the benchmark is split into
three categories :
• Mono-type Tasks represent a homogeneous setting that
involves only one type of robot but multiple robots of
the same type are allowed. These tasks are relatively
simple with GT ranging from 4-8 steps.
• Dual-type Tasks involve the collaboration between two
types of robots due to the limited capabilities of single-
type robots, with a GT step ranging from 8-12 steps.
• Trio-type Tasks show the most complex heteroge-
neous setting, necessitating the meticulous collaboration
among all three types of robots. These tasks place high
demands on the long-horizon inference capabilities of
LLM-based planners, with GT within 10-16 steps.
In total, our benchmark contains 32 mono-type tasks, 30
dual-type tasks, and 38 trio-type tasks.
B. Evaluation Metrics
In this paper, we adopt Success Rate (SR) and Average
Step (AS) as the evaluation metrics. For each task, we
manually design the optimal execution strategy steps as the
ground truth. A task is considered successful if all objects
reach their desired locations within twice the ground truth
step count. For failed tasks, the execution step count is
recorded as twice the ground truth plus one to facilitate
uniform statistics. In summary, we aim to achieve higher
success rates and fewer average steps.
C. Simulation Experiments
Experiment setting: Our method is validated in the
simulation environment of BEHAVIOR-1K platform [39],
employing gpt-4-0125-preview as LLM to conduct
all experiments. Considering the cost of the OpenAI API,
we select 40 tasks from all 100 tasks in the benchmark for
our experiments. These tasks are sourced from all 5 distinct
10211
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on January 26,2026 at 09:03:07 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 5 ---
TABLE II
QUANTITATIVE COMPARISON OF DIFFERENT METHODS ON DIFFERENT SUBSETS IN OUR BENCHMARK.
Method
Mono-type Task
Dual-type Task
Trio-type Task
Average
SR
AS
SR
AS
SR
AS
SR
AS
DMRS-1D [20]
0.700
10.6
0.467
18.0
0.667
20.7
0.600
17.2
DMRS-2D [20]
0.500
11.5
0.267
19.9
0.400
24.5
0.375
19.6
CMRS [7]
0.900
7.9
0.533
16.4
0.533
22.2
0.625
16.5
Primitive MCTS [38]
0.000
14.0
0.000
21.5
0.000
26.9
0.000
21.7
LLM-MCTS [28]
0.700
10.2
0.067
20.9
0.000
26.9
0.200
20.5
COHERENT w/o history
0.900
9.0
0.933
13.9
0.467
23.9
0.750
16.5
COHERENT (Ours)
0.900
7.4
1.000
11.9
1.000
16.1
0.975
12.4
Ground Truth (GT)
-
6.5
-
10.3
-
12.9
-
10.3
TABLE III
QUANTITATIVE COMPARISON OF DIFFERENT METHODS ON DIFFERENT SCENES IN OUR BENCHMARK.
Method
S1
S2
S3
S4
S5
Average
SR
AS
SR
AS
SR
AS
SR
AS
SR
AS
SR
AS
DMRS-1D [20]
0.500
17.4
0.625
15.8
0.625
18.3
0.750
15.1
0.500
19.3
0.600
17.2
DMRS-2D [20]
0.500
18.9
0.500
18.3
0.375
20.6
0.250
18.9
0.250
21.1
0.375
19.6
CMRS [7]
0.875
13.1
0.625
16.6
0.625
18.5
0.375
18.1
0.625
15.9
0.625
16.5
Primitive MCTS [38]
0.000
21.5
0.000
21.8
0.000
22.5
0.000
20.5
0.000
22.0
0.000
21.7
LLM-MCTS [28]
0.250
20.0
0.250
20.4
0.250
21.3
0.125
19.9
0.125
20.9
0.200
20.5
COHERENT w/o history
0.750
16.6
0.625
16.6
0.875
17.1
0.875
14.3
0.625
17.6
0.750
16.5
COHERENT (Ours)
1.000
13.1
1.000
11.4
1.000
11.9
1.000
11.4
0.875
14.0
0.975
12.4
Ground Truth (GT)
-
10.3
-
10.4
-
10.8
-
9.8
-
10.5
-
10.3
Instruction:   Put the meat on the grill. The meat is originally in the fridge.
Robotic Dog:
[movetowards] <fridge>
Robotic Dog:
 [open] <fridge>
Robotic Dog:
[grab] <meat>
Robotic Dog:
[movetowards] <basket>
Quadrotor: 
[takeoff_from] <room floor>
Quadrotor: 
[movetowards] <garden>
Quadrotor: 
[movetowards] <table>
Robotic Dog:
[movetowards] <meat>
Robotic Dog:
[putinto] <meat> into <basket>
Quadrotor: 
[land_on] <table>
Robotic Arm: 
[grab] <meat>
Robotic Arm:
[puton] <meat> on <grill>
(1)
(2)
(7)
(6)
(12)
(5)
(11)
(10)
(4)
(9)
(3)
(8)
Fig. 4.
A successful example of putting the meat on the grill in scenario S5.
simulation scenes in our benchmark. 8 tasks are verified in
each simulation scene, comprising 2 mono-type tasks, 3 dual-
type tasks, and 3 trio-type tasks. The selected tasks allow
for a comparison of our method with other baselines across
various types and levels of difficulty.
Compared methods: Based on the different communica-
tion architectures among multiple robots, we compare our
method with three other approaches. In addition to LLM-
based methods, we also compare two traditional tree search
algorithms in task planning to demonstrate the effectiveness
of our approach.
• DMRS-1D: We implement DMRS-1D baseline as a
variant of CoELA [20], which adopts a decentralized
multi-robot system framework, allowing robots to de-
termine the next step through dialogue. The last robot
summarizes all the dialogue content to reach the final
conclusion.
• DMRS-2D: Considering that robots speaking earlier
in a dialogue round have access to less information,
we design a two-round dialogue setting to mitigate the
impact of information disparity [20].
• CMRS: We design a primitive centralized multi-robot
system [7] incorporating only a decision-making LLM.
All information is stored in the prompt and then the
central LLM outputs executable actions.
• Primitive MCTS: We employ the primitive Monte
Carlo tree search algorithm [38] with a random rollout
strategy and the ground-truth reward function. The
actions of all robots collectively form the search space.
• LLM-MCTS: We compare an algorithm that integrates
LLM with the Monte Carlo method [28] to enhance the
effectiveness of primitive MCTS. LLMs are employed
to serve as π(a | h) in PUCT to guide action selection
during the simulation process.
Additionally, we conduct ablation studies to evaluate the
effectiveness of COHERENT without dialogue history in the
prompt of Task Assigner LLM.
Experimental Results: We conduct experiments across
various task types and different scenes in our benchmark.
As shown in Table II, compared to other methods, COHER-
ENT achieves the highest success rate and action execution
efficiency. Moreover, as the difficulty of the tasks increases,
the superiority of our method in terms of success rate
and average step becomes more pronounced. The results
10212
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on January 26,2026 at 09:03:07 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 6 ---
of our method significantly outperform the dialogue-based
decentralized method. It indicates that a global planning
strategy by a central planner is crucial for task planning in
heterogeneous multi-robot systems. From the results of the
CMRS, we discover that dividing the process into two phases
i.e., high-level planning and low-level action execution, al-
lows for more precise task allocation and mapping to specific
robot actions, as what our task assigner and robot executor
accomplish. We also compare with the traditional tree search
algorithm and its variant, and our approach still demonstrates
significant advantages. In the ablation study, the absence
of dialogue history in the prompt of Task Assigner LLM
means that the task execution process and the feedback
required to adjust the proposal plan cannot be recorded.
It results in a lack of continuity for a plan that requires
multiple steps to execute, thereby hindering the completion
of the final goal. As illustrated in Table III, even across
varied scenes, our method consistently demonstrates superior
performance. This indicates its strong generalizability to
different types of scenes. Figure 4 shows an example of our
method successfully accomplishing the task in S5.
Furthermore, by detailing several failure reasons, we con-
cretely analyze the problems with dialogue-based methods
as a decentralized communication framework.
Reason 1: The dialogue-based method is more appropriate
for robots to execute actions in parallel because each robot
tends to select its own actions to achieve the objective.
Lacking an understanding of other robots’ capabilities and
observations, it is challenging for each robot to make accu-
rate judgments about the actions others should execute. This
is the primary reason for the failure of such methods.
Reason 2: Decisions made during the robot discussion
process are not executed. However, subsequent robots tend
to plan the next actions based on the assumption that previous
actions in the dialogue have already been executed. This
results in hallucinatory actions not existing in the current
list of executable actions, causing failures in action parsing.
An example is shown below:
Subgoal: The robotic dog is holding the apple and is close to the
quadrotor. Put the apple into the quadrotor’s basket to transport to the
dining table (high surface).
...
Robotic Dog: I suggest <robotic dog> execute [putinto] <apple> into
<basket>. (Right)
Quadrotor: I suggest <quadrotor> execute [takeoff from] <kitchen
floor>. (Wrong. Because the previous action has not been executed.)
Reason 3: The actions resulting from discussions among
robots are often trapped in repetitive cycles, hindering
progress toward the ultimate objective. The issues stem from
decision-makers lacking comprehensive information and a
long-term plan.
D. Real-world Experiment
To demonstrate the effectiveness of COHERENT in the
real world, we conduct experiments with multiple hetero-
geneous robots in real-world scenes. We utilize our self-
developed swarm consisting of three quadrotors, a Unitree
“Quadrotor swarm plans its path 
for flying to the kitchen.”
“Robotic dog check door leading 
to the kichen.”
Successfully 
plan the path.
Door is closed so 
can’t cross. Please 
remake a plan.
“Robotic dog opens the door to 
let quadrotor swarm through.”
“Quadrotor swarm crosses the 
door and fly to the kitchen.”
“Robotic arm places the cookies 
and porridge into basket.”
“Quadrotor swarm flies back to 
the starting point.”
I've opened the 
door.
Instruction:   Go to the kitchen and get something to eat.
I’ve flown across 
the door.
Place cookies and 
porridge into basket.
Task Done!
Proposal
Execution
Feedback
Adjustment
Fig. 5.
Real-world Experiment: With the cooperation of the robotic dog
and robotic arm, the quadrotor swarm fly to the kitchen across a closed
door and take the cookies and porridge back which are on the kitchen table
initially. This task cannot be completed without the presence of any one of
the robots.
Aliengo robotic dog equipped with a small mechanical
arm on the back, and a Franka Panda robotic arm. The
quadrotor swarm and robotic dog use LiDAR mapping for
navigation, and the robotic arm is equipped with a wrist
RGB-D camera to capture visual information. Grounding-
DINO[40] is utilized for object detection to help grasping.
Besides, the communication between different robots and the
host computer is based on socket connections.
As shown in Figure 5, the user issues a voice command
Go to the kitchen and get something to
eat. The visual perception model identifies that the door to
the kitchen is closed. Furthermore, the Task Assigner LLM
decides to first have the robotic dog use its arm to open
the door rather than let the quadrotor swarm pass the door.
Then the quadrotor swarm collaborates with the robotic
arm fixed in the kitchen to bring the cookies back. Our
experiments prove that COHERENT can be extended to
real-world environments in a zero-shot manner and exhibits
generalization.
V. CONCLUSIONS
In this paper, we propose COHERENT, a novel frame-
work designed to address task planning in heterogeneous
multi-robot systems. Leveraging the reasoning capability of
LLMs, we facilitate precise task allocation and timely im-
provements through a continuous loop of proposal-execution-
feedback-adjustment between the task assigner and various
robot executors. Moreover, we propose a challenging bench-
mark specifically tailored for heterogeneous multi-robot task
planning , including 5 scenes and a total of 100 tasks across
three types. Our method achieves the best results on this
benchmark and has been successfully tested in the real world.
ACKNOWLEDGMENTS
This work is supported by the Shanghai AI Laboratory, the
National Key R&D Program of China (2022ZD0160102), the
National Natural Science Foundation of China (62376222),
and the Young Elite Scientists Sponsorship Program by
CAST (2023QNRC001).
10213
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on January 26,2026 at 09:03:07 UTC from IEEE Xplore.  Restrictions apply. 


--- Page 7 ---
REFERENCES
[1] J. Shi, C. Bai, H. He, L. Han, D. Wang, B. Zhao, X. Li, and X. Li,
“Robust quadrupedal locomotion via risk-averse policy learning,”
arXiv preprint arXiv:2308.09405, 2023.
[2] J. Gu, F. Xiang, X. Li, Z. Ling, X. Liu, T. Mu, Y. Tang, S. Tao, X. Wei,
Y. Yao et al., “Maniskill2: A unified benchmark for generalizable
manipulation skills,” arXiv preprint arXiv:2302.04659, 2023.
[3] R. Gong, X. Gao, Q. Gao, S. Shakiah, G. Thattai, and G. S. Sukhatme,
“Lemma: Learning language-conditioned multi-robot manipulation,”
IEEE Robotics and Automation Letters, 2023.
[4] A. Padalkar, A. Pooley, A. Jain, A. Bewley, A. Herzog, A. Ir-
pan, A. Khazatsky, A. Rai, A. Singh, A. Brohan et al., “Open
x-embodiment: Robotic learning datasets and rt-x models,” arXiv
preprint arXiv:2310.08864, 2023.
[5] H. R. Walke, K. Black, T. Z. Zhao, Q. Vuong, C. Zheng, P. Hansen-
Estruch, A. W. He, V. Myers, M. J. Kim, M. Du et al., “Bridgedata
v2: A dataset for robot learning at scale,” in Conference on Robot
Learning.
PMLR, 2023, pp. 1723–1736.
[6] T. Kojima, S. S. Gu, M. Reid, Y. Matsuo, and Y. Iwasawa, “Large
language models are zero-shot reasoners,” Advances in neural infor-
mation processing systems, vol. 35, pp. 22 199–22 213, 2022.
[7] W. Huang, P. Abbeel, D. Pathak, and I. Mordatch, “Language models
as zero-shot planners: Extracting actionable knowledge for embodied
agents,” in International Conference on Machine Learning.
PMLR,
2022, pp. 9118–9147.
[8] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal,
A. Neelakantan, P. Shyam, G. Sastry, A. Askell et al., “Language mod-
els are few-shot learners,” Advances in neural information processing
systems, vol. 33, pp. 1877–1901, 2020.
[9] Y. Ding, X. Zhang, C. Paxton, and S. Zhang, “Task and motion
planning with large language models for object rearrangement,” arXiv
preprint arXiv:2303.06247, 2023.
[10] W. Huang, C. Wang, R. Zhang, Y. Li, J. Wu, and L. Fei-Fei, “Voxposer:
Composable 3d value maps for robotic manipulation with language
models,” in Conference on Robot Learning.
PMLR, 2023, pp. 540–
562.
[11] J. Liang, W. Huang, F. Xia, P. Xu, K. Hausman, B. Ichter, P. Florence,
and A. Zeng, “Code as policies: Language model programs for em-
bodied control,” in 2023 IEEE International Conference on Robotics
and Automation (ICRA).
IEEE, 2023, pp. 9493–9500.
[12] P. Benavidez, M. Kumar, S. Agaian, and M. Jamshidi, “Design of a
home multi-robot system for the elderly and disabled,” in 2015 10th
System of Systems Engineering Conference (SoSE).
IEEE, 2015, pp.
392–397.
[13] C. Ju, J. Kim, J. Seol, and H. I. Son, “A review on multirobot systems
in agriculture,” Computers and Electronics in Agriculture, vol. 202, p.
107336, 2022.
[14] J. P. Queralta, J. Taipalmaa, B. C. Pullinen, V. K. Sarker, T. N.
Gia, H. Tenhunen, M. Gabbouj, J. Raitoharju, and T. Westerlund,
“Collaborative multi-robot search and rescue: Planning, coordination,
perception, and active vision,” Ieee Access, vol. 8, pp. 191 617–
191 643, 2020.
[15] Y. Du, S. Li, A. Torralba, J. B. Tenenbaum, and I. Mordatch, “Improv-
ing factuality and reasoning in language models through multiagent
debate,” arXiv preprint arXiv:2305.14325, 2023.
[16] Z. Wang, S. Mao, W. Wu, T. Ge, F. Wei, and H. Ji, “Unleashing cog-
nitive synergy in large language models: A task-solving agent through
multi-persona selfcollaboration,” arXiv preprint arXiv:2307.05300,
vol. 1, no. 2, p. 3, 2023.
[17] Y. Long, X. Li, W. Cai, and H. Dong, “Discuss before moving: Visual
language navigation via multi-expert discussions,” arXiv preprint
arXiv:2309.11382, 2023.
[18] W. Hunt, T. Godfrey, and M. D. Soorati, “Conversational language
models for human-in-the-loop multi-robot coordination,” in Proceed-
ings of the 23rd International Conference on Autonomous Agents and
Multiagent Systems, 2024, pp. 2809–2811.
[19] Z. Mandi, S. Jain, and S. Song, “Roco: Dialectic multi-robot col-
laboration with large language models,” in 2024 IEEE International
Conference on Robotics and Automation (ICRA).
IEEE, 2024, pp.
286–299.
[20] H. Zhang, W. Du, J. Shan, Q. Zhou, Y. Du, J. B. Tenenbaum, T. Shu,
and C. Gan, “Building cooperative embodied agents modularly with
large language models,” arXiv preprint arXiv:2307.02485, 2023.
[21] C. Aeronautiques, A. Howe, C. Knoblock, I. D. McDermott, A. Ram,
M. Veloso, D. Weld, D. W. SRI, A. Barrett, D. Christianson et al.,
“Pddl— the planning domain definition language,” Technical Report,
Tech. Rep., 1998.
[22] J. Hoffmann, “Ff: The fast-forward planning system,” AI magazine,
vol. 22, no. 3, pp. 57–57, 2001.
[23] M. Helmert, “The fast downward planning system,” Journal of Artifi-
cial Intelligence Research, vol. 26, pp. 191–246, 2006.
[24] C. R. Garrett, T. Lozano-P´erez, and L. P. Kaelbling, “Pddlstream:
Integrating symbolic planners and blackbox samplers via optimistic
adaptive planning,” in Proceedings of the International Conference on
Automated Planning and Scheduling, vol. 30, 2020, pp. 440–448.
[25] S. Pateria, B. Subagdja, A.-h. Tan, and C. Quek, “Hierarchical
reinforcement learning: A comprehensive survey,” ACM Computing
Surveys (CSUR), vol. 54, no. 5, pp. 1–35, 2021.
[26] O. Nachum, S. S. Gu, H. Lee, and S. Levine, “Data-efficient hi-
erarchical reinforcement learning,” Advances in neural information
processing systems, vol. 31, 2018.
[27] A. G. Barto and S. Mahadevan, “Recent advances in hierarchical
reinforcement learning,” Discrete event dynamic systems, vol. 13, no.
1-2, pp. 41–77, 2003.
[28] Z. Zhao, W. S. Lee, and D. Hsu, “Large language models as com-
monsense knowledge for large-scale task planning,” arXiv preprint
arXiv:2305.14078, 2023.
[29] A. Brohan, Y. Chebotar, C. Finn, K. Hausman, A. Herzog, D. Ho,
J. Ibarz, A. Irpan, E. Jang, R. Julian et al., “Do as i can, not as i say:
Grounding language in robotic affordances,” in Conference on Robot
Learning.
PMLR, 2023, pp. 287–318.
[30] D. Driess, F. Xia, M. S. Sajjadi, C. Lynch, A. Chowdhery, B. Ichter,
A. Wahid, J. Tompson, Q. Vuong, T. Yu et al., “Palm-e: An embodied
multimodal language model,” arXiv preprint arXiv:2303.03378, 2023.
[31] K. Lin, C. Agia, T. Migimatsu, M. Pavone, and J. Bohg, “Text2motion:
From natural language instructions to feasible plans,” arXiv preprint
arXiv:2303.12153, 2023.
[32] B. Yu, H. Kasaei, and M. Cao, “Co-navgpt: Multi-robot cooperative vi-
sual semantic navigation using large language models,” arXiv preprint
arXiv:2310.07937, 2023.
[33] X. Liu, P. Li, W. Yang, D. Guo, and H. Liu, “Leveraging large
language model for heterogeneous ad hoc teamwork collaboration,”
arXiv preprint arXiv:2406.12224, 2024.
[34] X. Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler, and A. Torralba,
“Virtualhome: Simulating household activities via programs,” in Pro-
ceedings of the IEEE Conference on Computer Vision and Pattern
Recognition, 2018, pp. 8494–8502.
[35] X. Puig, T. Shu, S. Li, Z. Wang, Y.-H. Liao, J. B. Tenenbaum, S. Fidler,
and A. Torralba, “Watch-and-help: A challenge for social perception
and human-ai collaboration,” arXiv preprint arXiv:2010.09890, 2020.
[36] Y. Chen, J. Arkin, Y. Zhang, N. Roy, and C. Fan, “Scalable multi-robot
collaboration with large language models: Centralized or decentralized
systems?” in 2024 IEEE International Conference on Robotics and
Automation (ICRA).
IEEE, 2024, pp. 4311–4317.
[37] S. S. Kannan, V. L. Venkatesh, and B.-C. Min, “Smart-llm: Smart
multi-agent robot task planning using large language models,” arXiv
preprint arXiv:2309.10062, 2023.
[38] C. B. Browne, E. Powley, D. Whitehouse, S. M. Lucas, P. I. Cowling,
P. Rohlfshagen, S. Tavener, D. Perez, S. Samothrakis, and S. Colton,
“A survey of monte carlo tree search methods,” IEEE Transactions on
Computational Intelligence and AI in games, vol. 4, no. 1, pp. 1–43,
2012.
[39] C. Li, R. Zhang, J. Wong, C. Gokmen, S. Srivastava, R. Mart´ın-Mart´ın,
C. Wang, G. Levine, M. Lingelbach, J. Sun et al., “Behavior-1k: A
benchmark for embodied ai with 1,000 everyday activities and realistic
simulation,” in Conference on Robot Learning. PMLR, 2023, pp. 80–
93.
[40] S. Liu, Z. Zeng, T. Ren, F. Li, H. Zhang, J. Yang, C. Li,
J. Yang, H. Su, J. Zhu et al., “Grounding dino: Marrying dino with
grounded pre-training for open-set object detection,” arXiv preprint
arXiv:2303.05499, 2023.
10214
Authorized licensed use limited to: Consortium - Saudi Arabia SDL. Downloaded on January 26,2026 at 09:03:07 UTC from IEEE Xplore.  Restrictions apply. 
