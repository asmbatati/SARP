# NEUROS-X
## Neuro-Symbolic Nexus ‚Äî Robotics AI Research Organization

> **Mission:** Design and build the universal cognitive middleware layer between humans and heterogeneous robotic systems ‚Äî abstracting robot middleware complexity so that any user can command, coordinate, and optimize any robot fleet through natural language and multi-modal intent alone.

---

## 1. Vision

### The Core Idea

NEUROS-X builds a **two-sided installable middleware stack**:

- **User Side** ‚Äî A cognitive HRI interface (web app / CLI / voice) where the user describes missions in natural language, images, or structured constraints
- **Robot Side** ‚Äî A lightweight agent node installed on each robot, advertising its capabilities, receiving allocated tasks, and executing them safely

Once configured, the user **only provides intent**. The system handles:
- Mission parsing and semantic grounding
- Task decomposition and multi-robot allocation
- Safety verification (pre-execution + runtime)
- Middleware translation (ROS 2, gRPC, MAVLink, micro-ROS)
- Closed-loop monitoring and failure recovery

### Why It Matters

Modern robotic systems require deep expertise in ROS, DDS, hardware drivers, safety protocols, and multi-robot coordination. NEUROS-X eliminates this barrier, enabling domain experts (firefighters, surgeons, facility managers) to operate complex heterogeneous fleets without robotics engineering knowledge.

### Design Philosophy: Neuro-Symbolic Nexus

The name and identity encode the two complementary paradigms at the system's core:

| Symbol | Meaning |
|--------|---------|
| **Neuro** | Neural / LLM reasoning ‚Äî flexible, commonsense-capable, multi-modal |
| **Symbolic** | Formal logic ‚Äî sound, verifiable, constraint-enforcing |
| **Nexus** | The fusion point ‚Äî where both paradigms produce a unified, safe decision |

The logo concept: **organic neural network complexity enclosed within a geometric shield / logic gate** ‚Äî representing the union of adaptive intelligence and formal rigor.

---

## 2. Five-Tier Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  TIER 1: Semantic Intent Layer                                    ‚îÇ
‚îÇ  Multi-modal input (text, voice, image, .md mission brief)       ‚îÇ
‚îÇ  VLM grounding ‚Üí formal mission specification (JSON/PDDL)        ‚îÇ
‚îÇ  3D Scene Graph construction ¬∑ Robot Resume registry             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  TIER 2: Cognitive Orchestration Layer                           ‚îÇ
‚îÇ  LLM reasoning ¬∑ Hierarchical Task Network (HTN) decomposition   ‚îÇ
‚îÇ  8 planning backends: PDDL, BT, DAG, HTN, STL, FSM, Code, YAML  ‚îÇ
‚îÇ  Task allocation via Robot Resume matching (URDF-derived)        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  TIER 3: Triple-Channel Safety Verification  ‚Üê PRIMARY CONTRIB   ‚îÇ
‚îÇ  Channel 1 (Formal): LTL model checking + PDDL preconditions     ‚îÇ
‚îÇ  Channel 2 (LLM CoT): 4 sub-reasoners, independent verdict       ‚îÇ
‚îÇ  Channel 3 (Runtime): CBF barrier monitoring + conformal bounds  ‚îÇ
‚îÇ  Corroborative fusion: Approve / Reject / Review (human-in-loop) ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  TIER 4: Tool Mediation & Skill Ontology Layer                   ‚îÇ
‚îÇ  MCP tool invocation ¬∑ Robot Skill Ontology                      ‚îÇ
‚îÇ  VLA execution bridge (symbolic plan ‚Üí motor tokens)             ‚îÇ
‚îÇ  Trigger-based expert agent loading (60-80% resource savings)    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  TIER 5: Heterogeneous HAL + Real-Time Monitoring               ‚îÇ
‚îÇ  Universal middleware bridge: ROS 2, ROS 1, gRPC, MAVLink        ‚îÇ
‚îÇ  PEFA loop: Proposal ‚Üí Execution ‚Üí Feedback ‚Üí Adjust            ‚îÇ
‚îÇ  Execution tracker ¬∑ Failure detection ¬∑ Re-planning trigger     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Research Papers by Tier:**

| Tier | NEUROS-X Component | First Paper | Venue Target |
|------|-------------------|-------------|-------------|
| Tier 3 | Triple-Channel Safety Verification | **SAFEMRS** (dual-channel) | IROS 2026 |
| Tier 2 | Cognitive Orchestration + Multi-Robot Planning | Future paper | ICRA 2027 |
| Tier 1 | Semantic Intent Grounding (VLM + Scene Graph) | Future paper | RA-L |
| Tier 4 | MCP Tool Mediation + VLA Bridge | Future paper | IROS 2027 |
| Tier 5 | HAL + PEFA Closed-Loop Monitoring | Future paper | ICRA 2028 |

---

## 3. GitHub Organization Structure

### Organization: `github.com/NEUROS-X`

All repositories migrated from `github.com/asmbatati` to the NEUROS-X organization upon public release.

---

### Repository Map

```
NEUROS-X/
‚îÇ
‚îú‚îÄ‚îÄ neuros-core/              ‚Üê Full 5-tier cognitive middleware (long-term goal)
‚îÇ
‚îú‚îÄ‚îÄ neuros-safemrs/           ‚Üê PAPER 1: Tier 3 dual-channel safety verification
‚îú‚îÄ‚îÄ neuros-sim/               ‚Üê Simulation worlds + multi-robot descriptions
‚îú‚îÄ‚îÄ neuros-docker/            ‚Üê Docker infrastructure + CI/CD
‚îÇ
‚îú‚îÄ‚îÄ neuros-agent/             ‚Üê ROS 2 LLM agent node (ROSA + LangChain + tools)
‚îú‚îÄ‚îÄ neuros-gui/               ‚Üê Web simulation interface (React + FastAPI)
‚îú‚îÄ‚îÄ neuros-demos/             ‚Üê Mission demonstrations (SAR, inspection, patrol)
‚îú‚îÄ‚îÄ neuros-bridge/            ‚Üê Middleware HAL (ROS 2, MAVLink, gRPC, micro-ROS)
‚îú‚îÄ‚îÄ neuros-benchmarking/      ‚Üê Evaluation & metrics framework
‚îÇ
‚îú‚îÄ‚îÄ neuros-planning/          ‚Üê Cognitive orchestration layer (future ICRA 2027)
‚îú‚îÄ‚îÄ neuros-grounding/         ‚Üê Semantic intent layer (future RA-L)
‚îÇ
‚îî‚îÄ‚îÄ neuros-x.github.io/       ‚Üê Organization website
```

---

## 4. Repository Specifications

### 4.1 `neuros-safemrs` ‚Äî Core Safety Verification Framework

> **Status:** Active ‚Äî IROS 2026 paper underway
> **Maps to:** NEUROS-X Tier 3

The primary research contribution: corroborative dual-channel (‚Üí triple-channel) pre-execution safety verification for LLM-based heterogeneous multi-robot task planning.

**Current state:** Python package (`safemrs/`) with 102-scenario benchmark, 51 passing unit tests, and confirmed results for Qwen3:8b and GPT-4o backends.

**Package structure:**

```
neuros-safemrs/                   (repo root)
‚îú‚îÄ‚îÄ safemrs/                      (Python package, pip-installable)
‚îÇ   ‚îú‚îÄ‚îÄ channel_formal/           Channel 1: LTL + PDDL + Deontic
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ltl_checker.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pddl_validator.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ deontic_checker.py
‚îÇ   ‚îú‚îÄ‚îÄ channel_llm/              Channel 2: 4 LLM sub-reasoners
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_reasoner.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ safety_reasoner.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sub_reasoners/
‚îÇ   ‚îú‚îÄ‚îÄ fusion/                   Corroborative fusion mechanism
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fusion.py             Approve/Reject/Review logic
‚îÇ   ‚îú‚îÄ‚îÄ benchmark/                102 YAML scenarios + evaluator
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scenarios/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluator.py          HDR, FPR, EffCov, ŒîC metrics
‚îÇ   ‚îî‚îÄ‚îÄ ros2_integration/         ROS 2 node + SafetyGate
‚îÇ       ‚îî‚îÄ‚îÄ safety_gate.py
‚îú‚îÄ‚îÄ experiments/                  Experiment runners + analysis scripts
‚îÇ   ‚îú‚îÄ‚îÄ reproduce.sh
‚îÇ   ‚îú‚îÄ‚îÄ run_llm_background.py
‚îÇ   ‚îú‚îÄ‚îÄ check_progress.py
‚îÇ   ‚îî‚îÄ‚îÄ analyze_results.py
‚îú‚îÄ‚îÄ tests/                        51 unit tests (pytest)
‚îú‚îÄ‚îÄ results/final/                Archived experiment CSVs
‚îÇ   ‚îú‚îÄ‚îÄ formal_only_qwen3:8b.csv
‚îÇ   ‚îú‚îÄ‚îÄ llm_only_qwen3:8b.csv
‚îÇ   ‚îú‚îÄ‚îÄ dual_qwen3:8b.csv
‚îÇ   ‚îú‚îÄ‚îÄ formal_only_gpt-4o.csv
‚îÇ   ‚îú‚îÄ‚îÄ llm_only_gpt-4o.csv
‚îÇ   ‚îî‚îÄ‚îÄ dual_gpt-4o.csv
‚îú‚îÄ‚îÄ latex/                        IROS 2026 paper (main.tex)
‚îî‚îÄ‚îÄ pyproject.toml
```

**Key metrics (confirmed):**

| Backend | HDR (Dual) | FPR (Dual) | EffCov | Latency |
|---------|:---:|:---:|:---:|:---:|
| Qwen3:8b (local) | 64.2% | **0.0%** | 87.7% | 69.3s |
| GPT-4o (cloud) | 75.5% | 2.0% | 96.1% | 5.2s |

---

### 4.2 `neuros-sim` ‚Äî Multi-Robot Simulation Environments

> **Status:** Partially active (extracted from SAFEMRS)
> **Maps to:** NEUROS-X Tier 5 (execution platform)

Gazebo Harmonic worlds, robot URDF/SDF descriptions, and ROS 2 launch orchestration for all NEUROS-X robot types. Kept simulation-agnostic from `neuros-safemrs` core.

**Supported robot types:**

| Robot | Type | Middleware | Status |
|-------|------|-----------|--------|
| Unitree Go2 | Quadruped | CHAMP + cmd_vel + EKF | ‚úÖ Active |
| PX4 x500 | UAV (multirotor) | MAVROS + XRCE-DDS | ‚úÖ Active |
| Clearpath Husky | Wheeled UGV | cmd_vel + Nav2 | üü° Planned |
| TurtleBot 4 | Wheeled UGV | cmd_vel + Nav2 | üü° Planned |
| Unitree H1 | Humanoid | whole-body controller | üü† Future |
| UR5e | Arm manipulator | MoveIt 2 + ros2_control | üü† Future |
| Franka Panda | Arm manipulator | MoveIt 2 + ros2_control | üü† Future |
| BlueROV2 | Marine AUV | MAVROS + ArduSub | üîµ Concept |

**Package structure:**

```
neuros-sim/
‚îú‚îÄ‚îÄ bringup/                      ROS 2 launch orchestration
‚îÇ   ‚îú‚îÄ‚îÄ launch/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sar_full.launch.py    Go2 + PX4 drone, shared world
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inspection.launch.py  Drone (exterior) + Go2 (interior)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patrol.launch.py      Multi-UGV facility patrol
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation.launch.py  Benchmarking setup
‚îÇ   ‚îú‚îÄ‚îÄ worlds/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sar_default.sdf       Default outdoor SAR world (current)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sar_inspection.sdf    Building inspection world (needed)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sar_wilderness.sdf    Outdoor wilderness (future)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ warehouse.sdf         Indoor manipulation (future)
‚îÇ   ‚îî‚îÄ‚îÄ config/
‚îÇ       ‚îú‚îÄ‚îÄ rviz/neuros.rviz
‚îÇ       ‚îî‚îÄ‚îÄ bridge_topics.yaml
‚îú‚îÄ‚îÄ robots/                       Per-robot ROS 2 packages
‚îÇ   ‚îú‚îÄ‚îÄ quadruped/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unitree_go2_description/   Go2 URDF + meshes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ unitree_go2_sim/           CHAMP controller config
‚îÇ   ‚îú‚îÄ‚îÄ uav/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ px4_x500_description/      PX4 x500 SDF + configs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ px4_models/                PX4 aircraft configs (4020, 4021, 4022)
‚îÇ   ‚îú‚îÄ‚îÄ ugv/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clearpath_husky_description/   Husky URDF + meshes (planned)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ turtlebot4_description/        TurtleBot 4 URDF (planned)
‚îÇ   ‚îú‚îÄ‚îÄ humanoid/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ unitree_h1_description/        H1 URDF + meshes (future)
‚îÇ   ‚îî‚îÄ‚îÄ manipulator/
‚îÇ       ‚îú‚îÄ‚îÄ ur5e_description/              UR5e URDF (future)
‚îÇ       ‚îî‚îÄ‚îÄ franka_description/            Franka Panda URDF (future)
‚îî‚îÄ‚îÄ drone_sim/                    PX4 SITL + MAVROS launch
    ‚îú‚îÄ‚îÄ launch/
    ‚îÇ   ‚îú‚îÄ‚îÄ drone.launch.py
    ‚îÇ   ‚îú‚îÄ‚îÄ gz_sim.launch.py
    ‚îÇ   ‚îî‚îÄ‚îÄ mavros.launch.py
    ‚îî‚îÄ‚îÄ mavros/
```

---

### 4.3 `neuros-docker` ‚Äî Docker & Infrastructure

> **Status:** Active (submodule under SAFEMRS)

Reproducible development environment: Ubuntu 24.04 + ROS 2 Jazzy + Gazebo Harmonic + PX4 SITL + XRCE-DDS + MAVROS.

**Design principles:**
- Ollama runs **on the host** (not in Docker) ‚Äî avoids 20+ GB in image
- Model weights never baked into image ‚Äî pulled at runtime
- Shared volume for workspace source + PX4

```
neuros-docker/
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.base     ROS 2 + Gazebo + PX4 + MAVROS + Python deps (~8-10 GB)
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile.dev      Extends base + VS Code + RQt + debug tools
‚îú‚îÄ‚îÄ docker-compose.yml      Multi-service: neuros + ollama (optional)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ docker_run.sh
‚îÇ   ‚îú‚îÄ‚îÄ entrypoint.sh
‚îÇ   ‚îú‚îÄ‚îÄ install.sh
‚îÇ   ‚îî‚îÄ‚îÄ install_ollama.sh   Separate: model weights download
‚îú‚îÄ‚îÄ requirements/
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ system_packages.txt
‚îî‚îÄ‚îÄ ci/
    ‚îú‚îÄ‚îÄ build.yml
    ‚îî‚îÄ‚îÄ test.yml
```

---

### 4.4 `neuros-agent` ‚Äî ROS 2 LLM Agent Node

> **Status:** Active (extracted from `ros2_agent_sim/ros2_agent`)
> **Maps to:** NEUROS-X Tier 2 + Tier 4

Standalone ROS 2 node powering natural language robot interaction. ROSA (NASA JPL) + LangChain dispatch tool calls to any connected robot, with the SAFEMRS safety gate as pre-execution middleware.

```
neuros-agent/
‚îú‚îÄ‚îÄ neuros_agent/
‚îÇ   ‚îú‚îÄ‚îÄ agent_node.py         Main node: LangChain + ROSA + safety gate
‚îÇ   ‚îú‚îÄ‚îÄ safety/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ safety_gate.py    SAFEMRS integration (dual/formal/passthrough)
‚îÇ   ‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ drone_tools.py    7 UAV tools via MAVROS
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ go2_tools.py      8 Go2 tools via cmd_vel/odom
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ manipulation_tools.py  MoveIt 2 arm tools (future)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vlm_tools.py      VLM scene analysis (Qwen2.5VL)
‚îÇ   ‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ system_prompt.py  Robot-aware system prompt
‚îÇ   ‚îî‚îÄ‚îÄ robot_resume/
‚îÇ       ‚îî‚îÄ‚îÄ resume_loader.py  Capability profile loader
‚îú‚îÄ‚îÄ config/agent_params.yaml
‚îú‚îÄ‚îÄ launch/agent.launch.py
‚îî‚îÄ‚îÄ setup.py
```

**Key ROS 2 parameters:**

| Parameter | Default | Options |
|-----------|---------|---------|
| `llm_model` | `qwen3:8b` | `gpt-4o`, `claude-3-5-haiku`, `llama3.1:8b` |
| `safety_mode` | `dual` | `dual`, `formal_only`, `passthrough` |
| `ollama_base_url` | `http://host.docker.internal:11434` | Any Ollama endpoint |

---

### 4.5 `neuros-gui` ‚Äî Web Simulation Interface

> **Status:** Active (extracted from `ros2_agent_sim/simulation_gui`)
> **Maps to:** NEUROS-X Tier 1 (intent input) + Tier 5 (monitoring)

React + FastAPI web application for scenario building, robot spawning, mission dispatch, and live safety monitoring.

```
neuros-gui/
‚îú‚îÄ‚îÄ frontend/                 React + Vite + Tailwind + Framer Motion
‚îÇ   ‚îî‚îÄ‚îÄ src/components/
‚îÇ       ‚îú‚îÄ‚îÄ ScenarioBuilder.jsx   Drag-drop robot + asset placement
‚îÇ       ‚îú‚îÄ‚îÄ MissionPanel.jsx      NL command input ‚Üí agent dispatch
‚îÇ       ‚îú‚îÄ‚îÄ SafetyDashboard.jsx   Live Approve/Reject/Review log
‚îÇ       ‚îî‚îÄ‚îÄ RobotMonitor.jsx      Per-robot pose + battery + status
‚îú‚îÄ‚îÄ backend/                  FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ main.py               REST endpoints + ROS 2 bridge
‚îÇ   ‚îú‚îÄ‚îÄ scenario_generator.py Auto-generate launch files from GUI state
‚îÇ   ‚îî‚îÄ‚îÄ ros2_bridge.py        Subscribe to safety gate + robot topics
‚îî‚îÄ‚îÄ docker-compose.gui.yml
```

---

### 4.6 `neuros-demos` ‚Äî Mission Demonstrations

> **Status:** Active (extracted from `ros2_agent_sim/sar_system`)
> **Maps to:** NEUROS-X Tier 5 (execution platform)

Self-contained preconfigured multi-robot mission scenarios. Each demo ships with its own launch file, Gazebo world config, documented ROSA prompts, and expected safety gate behavior.

```
neuros-demos/
‚îú‚îÄ‚îÄ sar/                      Search & Rescue (Go2 + PX4 drone)
‚îÇ   ‚îú‚îÄ‚îÄ launch/sar.launch.py
‚îÇ   ‚îî‚îÄ‚îÄ README.md             Prompts + expected safety gate responses
‚îú‚îÄ‚îÄ inspection/               Building inspection (drone + Go2)
‚îÇ   ‚îú‚îÄ‚îÄ launch/inspection.launch.py
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ patrol/                   Multi-UGV facility patrol
‚îÇ   ‚îú‚îÄ‚îÄ launch/patrol.launch.py
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ manipulation/             Table-top + mobile base (future)
‚îî‚îÄ‚îÄ shared/
    ‚îú‚îÄ‚îÄ evaluation.launch.py  RTF + performance logger
    ‚îî‚îÄ‚îÄ gps_bridge/           C++ GPS relay (shared dependency)
```

---

### 4.7 `neuros-bridge` ‚Äî Middleware Abstraction Layer

> **Status:** Planned (after SAFEMRS submission)
> **Maps to:** NEUROS-X Tier 5

Universal robot action interface: one API, any middleware. Converts `move_to()`, `get_pose()`, `stop()` to the appropriate protocol. Also generates Robot Resumes (capability profiles) from URDF/SDF for task allocation.

```
neuros-bridge/
‚îú‚îÄ‚îÄ neuros_bridge/
‚îÇ   ‚îú‚îÄ‚îÄ interface.py          Abstract base: move_to(), get_pose(), stop(), status()
‚îÇ   ‚îú‚îÄ‚îÄ resume.py             URDF/SDF ‚Üí Robot Resume (capability profile)
‚îÇ   ‚îî‚îÄ‚îÄ adapters/
‚îÇ       ‚îú‚îÄ‚îÄ ros2_adapter.py   cmd_vel + action servers (UGV / quadruped)
‚îÇ       ‚îú‚îÄ‚îÄ mavros_adapter.py MAVROS service calls (UAV)
‚îÇ       ‚îú‚îÄ‚îÄ mavlink_adapter.py Direct MAVLink (companion-less UAV)
‚îÇ       ‚îú‚îÄ‚îÄ grpc_adapter.py   gRPC robot API (future)
‚îÇ       ‚îî‚îÄ‚îÄ microros_adapter.py micro-ROS embedded (future)
‚îú‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ setup.py
```

---

### 4.8 `neuros-benchmarking` ‚Äî Evaluation Framework

> **Status:** Planned (metrics generalized from `neuros-safemrs`)
> **Maps to:** Cross-cutting ‚Äî supports all NEUROS-X papers

Standalone evaluation library for safety, planning, and execution quality across all NEUROS-X experiments. Generalizes the SAFEMRS benchmark runner into a reusable framework.

```
neuros-benchmarking/
‚îú‚îÄ‚îÄ neuros_benchmarking/
‚îÇ   ‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ safety_metrics.py    HDR, FPR, EffCov, ŒîC (from SAFEMRS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ planning_metrics.py  Task success, makespan, resource util
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ execution_metrics.py RTF, latency, failure rate
‚îÇ   ‚îú‚îÄ‚îÄ scenarios/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ safety/              102 SAFEMRS YAML scenarios (migrated)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ planning/            Multi-robot allocation scenarios (future)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ execution/           End-to-end mission scenarios (future)
‚îÇ   ‚îú‚îÄ‚îÄ runner.py                Batch experiment runner (CLI)
‚îÇ   ‚îî‚îÄ‚îÄ reporter.py              CSV ‚Üí matplotlib figures + LaTeX tables
‚îú‚îÄ‚îÄ experiments/
‚îî‚îÄ‚îÄ setup.py
```

---

### 4.9 `neuros-planning` ‚Äî Cognitive Orchestration (Future)

> **Status:** Planned ‚Äî ICRA 2027 paper

HTN/PDDL planning with multi-robot task allocation, multi-formalism support (PDDL, BT, DAG, HTN, STL, FSM), and coalition formation.

---

### 4.10 `neuros-grounding` ‚Äî Semantic Intent Layer (Future)

> **Status:** Planned ‚Äî RA-L paper

VLM-based multi-modal intent parsing, 3D scene graph construction, and formal mission specification generation from natural language + images.

---

## 5. Technology Stack

| Layer | Technology |
|-------|-----------|
| **LLM Inference (local)** | Ollama + Qwen3:8b (planning), Qwen2.5VL:7b (vision) |
| **LLM Inference (cloud)** | OpenAI GPT-4o, Anthropic Claude (comparison) |
| **LLM Framework** | LangChain + ROSA (NASA JPL) |
| **Formal Verification** | Python LTL/PDDL (production), Spot library (optional) |
| **Robot Middleware** | ROS 2 Jazzy (primary), MAVROS, XRCE-DDS |
| **Simulation** | Gazebo Harmonic, PX4 SITL |
| **UAV Stack** | PX4 ‚Üí XRCE-DDS ‚Üí MAVROS ‚Üí ROS 2 |
| **UGV Stack** | CHAMP ‚Üí ros2_control ‚Üí EKF ‚Üí ROS 2 |
| **Planning** | unified-planning (PDDL), py-trees (BT), custom HTN |
| **Safety Runtime** | Control Barrier Functions (CBF), conformal prediction |
| **GUI** | React + Vite + Tailwind + Framer Motion + FastAPI |
| **CI/CD** | GitHub Actions + pytest (51 tests) |
| **Containerization** | Docker + docker-compose (no model weights baked in) |
| **Evaluation** | Custom benchmark YAML + CSV pipeline + matplotlib |

---

## 6. Research Roadmap

### Active: SAFEMRS (IROS 2026 ‚Äî deadline March 2, 2026)

**Paper:** SAFEMRS: Corroborative Dual-Channel Pre-Execution Safety Verification for LLM-Based Heterogeneous Multi-Robot Task Planning

**Status:** ‚úÖ Experiments complete ¬∑ ‚úÖ LaTeX filled ¬∑ ‚è≥ Simulation figures needed ¬∑ ‚è≥ Submission pending

See [`remaining_tasks.md`](remaining_tasks.md) for detailed author task distribution.

---

### Next: SAFEMRS+ / Triple-Channel (IROS 2027)

Extend dual-channel to full triple-channel by adding:
- **Channel 3:** Runtime CBF enforcement (continuous, not just pre-execution)
- Conformal prediction for calibrated uncertainty bounds on safety decisions
- PEFA closed-loop re-planning on runtime violation detection

---

### Future: Cognitive Orchestration Paper (ICRA 2027)

Full Tier 2 implementation:
- LLM-driven HTN decomposition with hardware-aware allocation
- Robot Resume generation from URDF
- Multi-formalism planning (PDDL, BT, DAG)
- Multi-agent coordination (per-robot sub-agents + meta-coordinator)

---

## 7. Current Repository Mapping

| Current Repo / Path | Target NEUROS-X Repo | Transfer When |
|---------------------|---------------------|---------------|
| `asmbatati/SAFEMRS` ‚Üí `safemrs/` Python pkg | `NEUROS-X/neuros-safemrs` | After IROS submission |
| `asmbatati/SAFEMRS` ‚Üí `latex/` | Archived inside `NEUROS-X/neuros-safemrs` | After IROS submission |
| `asmbatati/SAFEMRS` ‚Üí `safemrs_sim/` | `NEUROS-X/neuros-sim` | After IROS submission |
| `asmbatati/ros2_agent_sim_docker` | `NEUROS-X/neuros-docker` | After IROS submission |
| `asmbatati/ros2_agent_sim` ‚Üí `ros2_agent/` | `NEUROS-X/neuros-agent` | After IROS submission |
| `asmbatati/ros2_agent_sim` ‚Üí `simulation_gui/` | `NEUROS-X/neuros-gui` | After IROS submission |
| `asmbatati/ros2_agent_sim` ‚Üí `sar_system/` | `NEUROS-X/neuros-demos` | After IROS submission |
| *(new)* | `NEUROS-X/neuros-bridge` | Phase 2 |
| *(new)* | `NEUROS-X/neuros-benchmarking` | Phase 2 |

---

## 8. Installation (Future Unified Setup)

```bash
# 1. Pull Docker environment
git clone https://github.com/NEUROS-X/neuros-docker.git

# 2. Clone workspace repos into shared volume
mkdir -p ~/neuros_ws/src && cd ~/neuros_ws/src
git clone https://github.com/NEUROS-X/neuros-safemrs.git
git clone https://github.com/NEUROS-X/neuros-sim.git
git clone https://github.com/NEUROS-X/neuros-agent.git
git clone https://github.com/NEUROS-X/neuros-demos.git

# 3. Install Ollama on HOST (never inside Docker)
curl -fsSL https://ollama.ai/install.sh | sh
ollama pull qwen3:8b
ollama pull qwen2.5vl:7b

# 4. Launch Docker environment
cd ~/neuros-docker && docker compose up -d

# 5. Enter container, build workspace
docker exec -it neuros bash
cd ~/neuros_ws && colcon build --symlink-install && source install/setup.bash

# 6. Install neuros-safemrs Python package
pip install -e src/neuros-safemrs/safemrs/

# 7. Launch a demo (e.g. SAR)
ros2 launch neuros_demos sar.launch.py

# 8. Launch neuros-agent with dual-channel safety gate
ros2 launch neuros_agent agent.launch.py \
  llm_model:=qwen3:8b safety_mode:=dual

# 9. (Optional) Launch web GUI
cd ~/neuros_ws/src/neuros-gui && docker compose -f docker-compose.gui.yml up
```

---

*NEUROS-X ‚Äî Neuro-Symbolic Nexus | Prince Sultan University Robotics & IoT Lab*
*Organization GitHub: https://github.com/NEUROS-X*
*First paper: https://github.com/asmbatati/SAFEMRS (‚Üí NEUROS-X/neuros-safemrs)*
